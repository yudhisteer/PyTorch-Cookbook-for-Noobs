{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d4e702f",
   "metadata": {},
   "source": [
    "# PyTorch Autograd: Automatic Differentiation\n",
    "\n",
    "## What is Autograd?\n",
    "\n",
    "\"_Neural networks (NNs) are a collection of nested functions that are executed on some input data. These functions are defined by **parameters** (consisting of weights and biases), which in PyTorch are stored in tensors._\"\n",
    "\n",
    "> Reference: https://docs.pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html\n",
    "\n",
    "## The Two-Step Training Process\n",
    "\n",
    "Training a NN happens in two steps:\n",
    "\n",
    "### 1. Forward Propagation\n",
    "In forward prop, the NN makes its best guess about the correct output. It runs the input data through each of its functions to make this guess.\n",
    "\n",
    "### 2. Backward Propagation (Backprop)\n",
    "In backprop, the NN adjusts its parameters proportionate to the error in its guess. It does this by:\n",
    "- Traversing backwards from the output\n",
    "- Collecting the derivatives of the error with respect to the parameters (gradients)\n",
    "- Optimizing the parameters using gradient descent\n",
    "\n",
    "---\n",
    "\n",
    "## Basic Example: Training Loop with ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6e67788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# import pretrained model\n",
    "from torchvision.models import resnet18, ResNet18_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "94ba0341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 62 tensors\n",
      "Data shape: torch.Size([1, 3, 64, 64]) -> 4 dimensions\n",
      "Labels shape: torch.Size([1, 1000]) -> 2 dimensions\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 1: Load a pretrained model and create dummy data\n",
    "# =============================================================================\n",
    "\n",
    "# Load ResNet18 with pretrained weights (trained on ImageNet)\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# Create random input data simulating a batch of images\n",
    "# Shape: (batch_size, channels, height, width)\n",
    "data = torch.rand(1, 3, 64, 64)  # 1 image, 3 color channels (RGB), 64x64 pixels\n",
    "\n",
    "# Create random labels (ImageNet has 1000 classes)\n",
    "# Shape: (batch_size, num_classes)\n",
    "labels = torch.rand(1, 1000)  # 1 sample with 1000 class scores\n",
    "\n",
    "# Inspect what we've created\n",
    "print(\"Model parameters:\", len(list(model.parameters())), \"tensors\")\n",
    "print(\"Data shape:\", data.shape, \"->\", data.ndim, \"dimensions\")\n",
    "print(\"Labels shape:\", labels.shape, \"->\", labels.ndim, \"dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0abd97d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape: torch.Size([1, 1000])\n",
      "Prediction range: [-2.61, 2.59]\n",
      "Has gradient function: True\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 2: Forward Pass - Get model predictions\n",
    "# =============================================================================\n",
    "\n",
    "# Pass input through the model to get predictions\n",
    "# This builds the computation graph that autograd will use for backprop\n",
    "prediction = model(data)\n",
    "\n",
    "print(\"Prediction shape:\", prediction.shape)  # [1, 1000] - scores for each class\n",
    "print(\"Prediction range:\", f\"[{prediction.min().item():.2f}, {prediction.max().item():.2f}]\")\n",
    "\n",
    "# Note: prediction has grad_fn because it's the result of differentiable operations\n",
    "print(\"Has gradient function:\", prediction.grad_fn is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1e1c6944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss tensor: tensor(-500.8209, grad_fn=<SumBackward0>)\n",
      "Loss value: -500.8209\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 3: Compute the Loss\n",
    "# =============================================================================\n",
    "\n",
    "# Calculate loss (error) between predictions and actual labels\n",
    "# Note: This is a simplified loss for demonstration. In practice, use:\n",
    "# - nn.CrossEntropyLoss() for classification\n",
    "# - nn.MSELoss() for regression\n",
    "loss = (prediction - labels).sum()\n",
    "\n",
    "print(\"Loss tensor:\", loss)\n",
    "print(f\"Loss value: {loss.item():.4f}\")\n",
    "\n",
    "# Understanding grad_fn:\n",
    "# The 'grad_fn=<SumBackward0>' shows this tensor was created by a sum operation.\n",
    "# PyTorch tracks this computation history (the \"computation graph\") so it can\n",
    "# automatically compute gradients during backpropagation.\n",
    "# \n",
    "# When you call loss.backward(), PyTorch:\n",
    "# 1. Starts from this loss tensor\n",
    "# 2. Follows the grad_fn chain backwards through all operations\n",
    "# 3. Computes gradients for all tensors with requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "add19962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First parameter shape: torch.Size([64, 3, 7, 7])\n",
      "Gradients computed: True\n",
      "Gradient shape: torch.Size([64, 3, 7, 7])\n",
      "Gradient shape matches parameter: True\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 4: Backward Pass - Compute Gradients\n",
    "# =============================================================================\n",
    "\n",
    "# This is where the magic happens!\n",
    "# backward() computes the gradient of loss with respect to ALL model parameters\n",
    "loss.backward()\n",
    "\n",
    "# After this call, each parameter tensor in the model has a .grad attribute\n",
    "# containing the gradient (partial derivative) of the loss with respect to that parameter\n",
    "\n",
    "# Let's verify gradients were computed\n",
    "# model.parameters() returns an iterator over all learnable parameters\n",
    "# next() gets the first one (ResNet18's first conv layer: 64 filters, 3 channels, 7x7 kernel)\n",
    "first_param = next(model.parameters())\n",
    "\n",
    "print(f\"First parameter shape: {first_param.shape}\")  # torch.Size([64, 3, 7, 7])\n",
    "print(f\"Gradients computed: {first_param.grad is not None}\")\n",
    "\n",
    "# The gradient has the SAME shape as the parameter\n",
    "# Each weight gets its own gradient value telling it how to change to reduce loss\n",
    "print(f\"Gradient shape: {first_param.grad.shape}\")  # torch.Size([64, 3, 7, 7])\n",
    "print(f\"Gradient shape matches parameter: {first_param.grad.shape == first_param.shape}\")\n",
    "\n",
    "#   - After backward(), every parameter has a .grad attribute containing its gradient\n",
    "#   - The gradient has the same shape as the parameter (each weight gets its own gradient value)\n",
    "#   - This gradient tells us: \"how much should this weight change to reduce the loss?\"\n",
    "\n",
    "#   Key insight: The gradient shape always matches the parameter shape because each individual weight needs its own update direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "baf2a0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Optimizer tracks 62 parameter tensors\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 5: Create Optimizer\n",
    "# =============================================================================\n",
    "\n",
    "# The optimizer uses the computed gradients to update model parameters\n",
    "# SGD = Stochastic Gradient Descent\n",
    "\n",
    "# Key hyperparameters:\n",
    "# - lr (learning rate): Step size for each update (smaller = more stable, slower)\n",
    "# - momentum: Helps accelerate SGD and dampen oscillations\n",
    "\n",
    "optim = torch.optim.SGD(params=model.parameters(), lr=1e-2, momentum=0.9)\n",
    "\n",
    "print(\"Optimizer:\", optim)\n",
    "print(\"\\nOptimizer tracks\", len(optim.param_groups[0]['params']), \"parameter tensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "889b7628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters updated: True\n",
      "Max change: 0.000100\n",
      "Mean change: 0.000008\n",
      "Num values changed: 8228 / 9408\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 6: Update Weights (Gradient Descent)\n",
    "# =============================================================================\n",
    "\n",
    "# Get a parameter's value before update\n",
    "# - model.parameters() returns a generator/iterator over all parameters\n",
    "# - next() gets the first parameter from that iterator (conv1 weights)\n",
    "# - detach(): Removes from computation graph (no grad_fn)\n",
    "# - clone(): Creates a copy in new memory so we keep the old values\n",
    "param_before = next(model.parameters()).detach().clone()\n",
    "\n",
    "# optimizer.step() updates all parameters using the computed gradients\n",
    "# For SGD: new_param = old_param - lr * gradient\n",
    "optim.step()\n",
    "\n",
    "# Verify parameters changed\n",
    "param_after = next(model.parameters()).detach()\n",
    "\n",
    "# Check if ANY values changed (not just first 5)\n",
    "print(f\"Parameters updated: {not torch.equal(param_before, param_after)}\")\n",
    "\n",
    "# Show the actual difference - small changes are expected with lr=0.01\n",
    "diff = (param_after - param_before).abs()\n",
    "print(f\"Max change: {diff.max().item():.6f}\")\n",
    "print(f\"Mean change: {diff.mean().item():.6f}\")\n",
    "print(f\"Num values changed: {(diff > 0).sum().item()} / {diff.numel()}\")\n",
    "\n",
    "# IMPORTANT: In a real training loop, you should also call:\n",
    "# optim.zero_grad()  # Clear old gradients before next backward pass\n",
    "# This is covered in detail later in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09ce11e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Understanding Gradient Computation\n",
    "\n",
    "Let's see exactly how autograd computes gradients using a simple mathematical example.\n",
    "\n",
    "> Reference: https://docs.pytorch.org/docs/stable/notes/autograd.html\n",
    "\n",
    "### Mathematical Example\n",
    "\n",
    "We'll compute gradients for: **Q = 3a^3 - b^2**\n",
    "\n",
    "Using calculus:\n",
    "- dQ/da = 9a^2\n",
    "- dQ/db = -2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7c5e13fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensors:\n",
      "a = [2.0, 3.0]\n",
      "b = [6.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "# Create tensors with requires_grad=True to track computations\n",
    "# These are our \"learnable parameters\"\n",
    "\n",
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)\n",
    "\n",
    "print(\"Input tensors:\")\n",
    "print(f\"a = {a.data.tolist()}\")  # [2, 3]\n",
    "print(f\"b = {b.data.tolist()}\")  # [6, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "75402114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q = tensor([-12.,  65.], grad_fn=<SubBackward0>)\n",
      "Q.shape = torch.Size([2])\n",
      "Q.grad_fn = <SubBackward0 object at 0x70d4daba6e00>\n"
     ]
    }
   ],
   "source": [
    "# Compute Q = 3*a^3 - b^2\n",
    "# PyTorch builds a computation graph as we perform operations\n",
    "\n",
    "Q = 3*a**3 - b**2\n",
    "\n",
    "# Q[0] = 3*(2^3) - (6^2) = -12\n",
    "# Q[1] = 3*(3^3) - (4^2) = 65\n",
    "\n",
    "print(\"Q =\", Q)\n",
    "print(f\"Q.shape = {Q.shape}\") # [5, 5]\n",
    "print(f\"Q.grad_fn = {Q.grad_fn}\")  # Shows the operation that created Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "eeb09a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call backward to compute gradients\n",
    "# Since Q is a vector (not a scalar), we need to reduce it first\n",
    "# Using Q.sum() effectively means we want dQ_total/da and dQ_total/db\n",
    "# where Q_total = Q[0] + Q[1]\n",
    "\n",
    "Q.sum().backward()\n",
    "\n",
    "# Alternative: pass a gradient vector to backward()\n",
    "# external_grad = torch.tensor([1., 1.])\n",
    "# Q.backward(gradient=external_grad)  # Same result as Q.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3d051bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying gradients:\n",
      "----------------------------------------\n",
      "Expected dQ/da = 9*a^2 = [36.0, 81.0]\n",
      "Computed a.grad       = [36.0, 81.0]\n",
      "Match: True\n",
      "\n",
      "Expected dQ/db = -2*b = [-12.0, -8.0]\n",
      "Computed b.grad       = [-12.0, -8.0]\n",
      "Match: True\n"
     ]
    }
   ],
   "source": [
    "# Verify the gradients are mathematically correct\n",
    "# dQ/da = 9*a^2, dQ/db = -2*b\n",
    "\n",
    "print(\"Verifying gradients:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# For a = [2, 3]: dQ/da = 9*a^2 = [9*4, 9*9] = [36, 81]\n",
    "expected_a_grad = 9 * a**2\n",
    "print(f\"Expected dQ/da = 9*a^2 = {expected_a_grad.data.tolist()}\")\n",
    "print(f\"Computed a.grad       = {a.grad.tolist()}\")\n",
    "print(f\"Match: {torch.allclose(a.grad, expected_a_grad.detach())}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# For b = [6, 4]: dQ/db = -2*b = [-12, -8]\n",
    "expected_b_grad = -2 * b\n",
    "print(f\"Expected dQ/db = -2*b = {expected_b_grad.data.tolist()}\")\n",
    "print(f\"Computed b.grad       = {b.grad.tolist()}\")\n",
    "print(f\"Match: {torch.allclose(b.grad, expected_b_grad.detach())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ovwohimkncc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Gradient Propagation Rules\n",
    "\n",
    "### requires_grad Propagation\n",
    "\n",
    "The output tensor of an operation will require gradients if **any** input tensor has `requires_grad=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "617eaf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = x + y\n",
      "  x.requires_grad = False\n",
      "  y.requires_grad = False\n",
      "  a.requires_grad = False\n",
      "\n",
      "b = x + z\n",
      "  x.requires_grad = False\n",
      "  z.requires_grad = True\n",
      "  b.requires_grad = True\n",
      "  b.grad_fn = <AddBackward0 object at 0x70d4daba7370>\n"
     ]
    }
   ],
   "source": [
    "# Demonstrating requires_grad propagation\n",
    "\n",
    "x = torch.rand(5, 5)                           # No gradients\n",
    "y = torch.rand(5, 5)                           # No gradients\n",
    "z = torch.rand((5, 5), requires_grad=True)     # Requires gradients\n",
    "\n",
    "# x + y: Neither input requires gradients -> output doesn't require gradients\n",
    "a = x + y\n",
    "print(f\"a = x + y\")\n",
    "print(f\"  x.requires_grad = {x.requires_grad}\")\n",
    "print(f\"  y.requires_grad = {y.requires_grad}\")\n",
    "print(f\"  a.requires_grad = {a.requires_grad}\")  # False\n",
    "\n",
    "print()\n",
    "\n",
    "# x + z: One input requires gradients -> output requires gradients\n",
    "b = x + z\n",
    "print(f\"b = x + z\")\n",
    "print(f\"  x.requires_grad = {x.requires_grad}\")\n",
    "print(f\"  z.requires_grad = {z.requires_grad}\")\n",
    "print(f\"  b.requires_grad = {b.requires_grad}\")  # True\n",
    "print(f\"  b.grad_fn = {b.grad_fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n3h5qgti6yg",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Freezing Parameters (Transfer Learning)\n",
    "\n",
    "In transfer learning / fine-tuning, we often want to:\n",
    "1. **Freeze** most of the pretrained model (no gradient updates)\n",
    "2. **Train only** the final classification layer(s)\n",
    "\n",
    "This saves computation and prevents overfitting when you have limited data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a8e56c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters before freezing: 11,689,512\n",
      "Trainable parameters after freezing: 0\n",
      "Total frozen parameters: 62\n",
      "\n",
      "Sample frozen parameters:\n",
      "  conv1.weight: requires_grad=False\n",
      "  bn1.weight: requires_grad=False\n",
      "  bn1.bias: requires_grad=False\n",
      "  layer1.0.conv1.weight: requires_grad=False\n",
      "  layer1.0.bn1.weight: requires_grad=False\n",
      "  layer1.0.bn1.bias: requires_grad=False\n",
      "  layer1.0.conv2.weight: requires_grad=False\n",
      "  layer1.0.bn2.weight: requires_grad=False\n",
      "  layer1.0.bn2.bias: requires_grad=False\n",
      "  layer1.1.conv1.weight: requires_grad=False\n",
      "  layer1.1.bn1.weight: requires_grad=False\n",
      "  layer1.1.bn1.bias: requires_grad=False\n",
      "  layer1.1.conv2.weight: requires_grad=False\n",
      "  layer1.1.bn2.weight: requires_grad=False\n",
      "  layer1.1.bn2.bias: requires_grad=False\n",
      "  layer2.0.conv1.weight: requires_grad=False\n",
      "  layer2.0.bn1.weight: requires_grad=False\n",
      "  layer2.0.bn1.bias: requires_grad=False\n",
      "  layer2.0.conv2.weight: requires_grad=False\n",
      "  layer2.0.bn2.weight: requires_grad=False\n",
      "  layer2.0.bn2.bias: requires_grad=False\n",
      "  layer2.0.downsample.0.weight: requires_grad=False\n",
      "  layer2.0.downsample.1.weight: requires_grad=False\n",
      "  layer2.0.downsample.1.bias: requires_grad=False\n",
      "  layer2.1.conv1.weight: requires_grad=False\n",
      "  layer2.1.bn1.weight: requires_grad=False\n",
      "  layer2.1.bn1.bias: requires_grad=False\n",
      "  layer2.1.conv2.weight: requires_grad=False\n",
      "  layer2.1.bn2.weight: requires_grad=False\n",
      "  layer2.1.bn2.bias: requires_grad=False\n",
      "  layer3.0.conv1.weight: requires_grad=False\n",
      "  layer3.0.bn1.weight: requires_grad=False\n",
      "  layer3.0.bn1.bias: requires_grad=False\n",
      "  layer3.0.conv2.weight: requires_grad=False\n",
      "  layer3.0.bn2.weight: requires_grad=False\n",
      "  layer3.0.bn2.bias: requires_grad=False\n",
      "  layer3.0.downsample.0.weight: requires_grad=False\n",
      "  layer3.0.downsample.1.weight: requires_grad=False\n",
      "  layer3.0.downsample.1.bias: requires_grad=False\n",
      "  layer3.1.conv1.weight: requires_grad=False\n",
      "  layer3.1.bn1.weight: requires_grad=False\n",
      "  layer3.1.bn1.bias: requires_grad=False\n",
      "  layer3.1.conv2.weight: requires_grad=False\n",
      "  layer3.1.bn2.weight: requires_grad=False\n",
      "  layer3.1.bn2.bias: requires_grad=False\n",
      "  layer4.0.conv1.weight: requires_grad=False\n",
      "  layer4.0.bn1.weight: requires_grad=False\n",
      "  layer4.0.bn1.bias: requires_grad=False\n",
      "  layer4.0.conv2.weight: requires_grad=False\n",
      "  layer4.0.bn2.weight: requires_grad=False\n",
      "  layer4.0.bn2.bias: requires_grad=False\n",
      "  layer4.0.downsample.0.weight: requires_grad=False\n",
      "  layer4.0.downsample.1.weight: requires_grad=False\n",
      "  layer4.0.downsample.1.bias: requires_grad=False\n",
      "  layer4.1.conv1.weight: requires_grad=False\n",
      "  layer4.1.bn1.weight: requires_grad=False\n",
      "  layer4.1.bn1.bias: requires_grad=False\n",
      "  layer4.1.conv2.weight: requires_grad=False\n",
      "  layer4.1.bn2.weight: requires_grad=False\n",
      "  layer4.1.bn2.bias: requires_grad=False\n",
      "  fc.weight: requires_grad=False\n",
      "  fc.bias: requires_grad=False\n"
     ]
    }
   ],
   "source": [
    "# Load a fresh pretrained model\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# numel() returns the total number of elements in a tensor.\n",
    "# Each parameter p is a tensor with a shape (e.g., a weight matrix of shape (512, 256) has 131,072 elements). \n",
    "# Using numel() counts all scalar values, giving you the actual parameter count.\n",
    "# Without it, you'd just count the number of parameter tensors, not the total trainable parameters.\n",
    "\n",
    "# Check initial state - all parameters require gradients\n",
    "trainable_before = 0\n",
    "for p in model.parameters():\n",
    "    if p.requires_grad:\n",
    "        trainable_before += p.numel()\n",
    "print(f\"Trainable parameters before freezing: {trainable_before:,}\")\n",
    "\n",
    "# Freeze ALL parameters in the network\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "trainable_after = 0\n",
    "for p in model.parameters():\n",
    "    if p.requires_grad:\n",
    "        trainable_after += p.numel()\n",
    "print(f\"Trainable parameters after freezing: {trainable_after:,}\")\n",
    "\n",
    "frozen_params = [p for p in model.parameters() if not p.requires_grad]\n",
    "print(f\"Total frozen parameters: {len(frozen_params)}\")\n",
    "\n",
    "# show a frozen parameters\n",
    "print(\"\\nSample frozen parameters:\")\n",
    "for name, param in list(model.named_parameters()):\n",
    "    print(f\"  {name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f486c37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original classifier: Linear(in_features=512, out_features=1000, bias=True)\n",
      "New classifier: Linear(in_features=512, out_features=10, bias=True)\n",
      "\n",
      "Trainable parameters after replacing fc: 5,130\n",
      "(That's 5120 weights + 10 biases)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "# Replace the classifier (last layer(  fc.weight: requires_grad=False, fc.bias: requires_grad=False  )) with a new one for our task\n",
    "# Original: 512 features -> 1000 ImageNet classes\n",
    "# New: 512 features -> 10 classes (for our custom dataset)\n",
    "\n",
    "print(f\"Original classifier: {model.fc}\")\n",
    "\n",
    "model.fc = nn.Linear(512, 10)  # New layer - requires_grad=True by default!\n",
    "\n",
    "print(f\"New classifier: {model.fc}\")\n",
    "\n",
    "# Count trainable parameters - only the new fc layer\n",
    "trainable_final = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTrainable parameters after replacing fc: {trainable_final:,}\")\n",
    "print(f\"(That's {model.fc.weight.numel()} weights + {model.fc.bias.numel()} biases)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9543615e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters passed to optimizer: 62\n",
      "Parameters that will be updated: 2\n",
      "Parameters that are frozen: 60\n",
      "\n",
      "Trainable parameter names:\n",
      "  fc.weight: shape=[10, 512]\n",
      "  fc.bias: shape=[10]\n"
     ]
    }
   ],
   "source": [
    "# Create optimizer - even though we pass all parameters,\n",
    "# only those with requires_grad=True will be updated\n",
    "\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=1e-2, momentum=0.9)\n",
    "\n",
    "# Let's verify: check which parameters will actually be updated\n",
    "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "frozen_params = [p for p in model.parameters() if not p.requires_grad]\n",
    "\n",
    "print(f\"Parameters passed to optimizer: {len(list(model.parameters()))}\")\n",
    "print(f\"Parameters that will be updated: {len(trainable_params)}\")\n",
    "print(f\"Parameters that are frozen: {len(frozen_params)}\")\n",
    "\n",
    "# Better practice: only pass trainable parameters to optimizer\n",
    "# This is more efficient and clearer:\n",
    "# optimizer = optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9)\n",
    "\n",
    "print(\"\\nTrainable parameter names:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"  {name}: shape={list(param.shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u9h2o4t952q",
   "metadata": {},
   "source": [
    "## Disabling Gradient Tracking with torch.no_grad()\n",
    "\n",
    "When performing inference (predictions), we don't need to compute gradients. This saves memory and speeds up computation. Use `torch.no_grad()` or `torch.inference_mode()` for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "o4gua23g4rh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With gradient tracking:\n",
      "  y = tensor([2., 4., 6.], grad_fn=<MulBackward0>)\n",
      "  y.requires_grad = True\n",
      "  y.grad_fn = <MulBackward0 object at 0x70d4dabf7c40>\n"
     ]
    }
   ],
   "source": [
    "# Demonstrating torch.no_grad() context manager\n",
    "\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "\n",
    "# Normal operation - gradients are tracked\n",
    "y = x * 2\n",
    "print(f\"With gradient tracking:\")\n",
    "print(f\"  y = {y}\")\n",
    "print(f\"  y.requires_grad = {y.requires_grad}\")\n",
    "print(f\"  y.grad_fn = {y.grad_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e9881a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Without gradient tracking (torch.no_grad()):\n",
      "  z = tensor([2., 4., 6.])\n",
      "  z.requires_grad = False\n",
      "  z.grad_fn = None\n"
     ]
    }
   ],
   "source": [
    "# Inside no_grad() context - no gradient tracking\n",
    "with torch.no_grad():\n",
    "    z = x * 2\n",
    "    print(f\"\\nWithout gradient tracking (torch.no_grad()):\")\n",
    "    print(f\"  z = {z}\")\n",
    "    print(f\"  z.requires_grad = {z.requires_grad}\")\n",
    "    print(f\"  z.grad_fn = {z.grad_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "faade9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using inference_mode():\n",
      "  w = tensor([2., 4., 6.])\n",
      "  w.requires_grad = False\n"
     ]
    }
   ],
   "source": [
    "# inference_mode() is even faster than no_grad() (recommended for inference)\n",
    "with torch.inference_mode():\n",
    "    w = x * 2\n",
    "    print(f\"\\nUsing inference_mode():\")\n",
    "    print(f\"  w = {w}\")\n",
    "    print(f\"  w.requires_grad = {w.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b10c58e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inference output shape: torch.Size([1, 1000])\n",
      "Output requires_grad: False\n"
     ]
    }
   ],
   "source": [
    "# Common use case: evaluating model during training\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model.eval()  # Set model to evaluation mode (affects dropout, batchnorm, etc.)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # No gradients computed - faster and uses less memory\n",
    "    test_input = torch.rand(1, 3, 64, 64)\n",
    "    output = model(test_input)\n",
    "    print(f\"\\nInference output shape: {output.shape}\")\n",
    "    print(f\"Output requires_grad: {output.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xi5yviwlm8j",
   "metadata": {},
   "source": [
    "## The Importance of zero_grad()\n",
    "\n",
    "**CRITICAL**: PyTorch accumulates gradients by default! If you don't call `optimizer.zero_grad()` before each backward pass, gradients from previous iterations will add up, leading to incorrect updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "849238wbxkm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After first backward: x.grad = tensor([2., 4., 6.])\n"
     ]
    }
   ],
   "source": [
    "# Demonstrating gradient accumulation problem\n",
    "\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "\n",
    "# First backward pass\n",
    "y1 = (x ** 2).sum()\n",
    "y1.backward()\n",
    "print(f\"After first backward: x.grad = {x.grad}\")  # Should be [2, 4, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "45c7b0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After second backward (no zero_grad): x.grad = tensor([ 4.,  8., 12.])\n"
     ]
    }
   ],
   "source": [
    "# Second backward pass WITHOUT zeroing gradients\n",
    "y2 = (x ** 2).sum()\n",
    "y2.backward()\n",
    "print(f\"After second backward (no zero_grad): x.grad = {x.grad}\")  # [4, 8, 12] - DOUBLED!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3ef04ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After third backward (with zero_grad): x.grad = tensor([ 6., 12., 18.])\n"
     ]
    }
   ],
   "source": [
    "# Third backward pass WITH zeroing gradients\n",
    "# x.grad.zero_()  # Zero the gradients manually as .zero_grad() is used for optimizer\n",
    "y3 = (x ** 2).sum()\n",
    "y3.backward()\n",
    "print(f\"After third backward (with zero_grad): x.grad = {x.grad}\")  # [2, 4, 6] - Correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8jg06q1dris",
   "metadata": {},
   "source": [
    "### Complete Training Loop Pattern\n",
    "\n",
    "Here's the standard pattern you should follow for training neural networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cq34jweg8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loop for 3 epochs:\n",
      "\n",
      "Epoch 1: Loss = 0.7815\n",
      "Epoch 2: Loss = 0.7499\n",
      "Epoch 3: Loss = 0.7202\n",
      "\n",
      "Key takeaway: Always call optimizer.zero_grad() BEFORE loss.backward()\n"
     ]
    }
   ],
   "source": [
    "# Complete training loop example with a simple model\n",
    "\n",
    "# Create a simple linear model\n",
    "simple_model = nn.Linear(10, 2)\n",
    "criterion = nn.MSELoss()  # Use proper loss function, not just sum of differences\n",
    "optimizer = optim.SGD(simple_model.parameters(), lr=0.01)\n",
    "\n",
    "# Generate some dummy data\n",
    "inputs = torch.randn(5, 10)   # 5 samples, 10 features each\n",
    "targets = torch.randn(5, 2)   # 5 samples, 2 outputs each\n",
    "\n",
    "print(\"Training loop for 3 epochs:\\n\")\n",
    "\n",
    "# Always call optimizer.zero_grad() BEFORE loss.backward()\n",
    "\n",
    "for epoch in range(3):\n",
    "    # ============================================\n",
    "    # STANDARD TRAINING LOOP - MEMORIZE THIS ORDER\n",
    "    # ============================================\n",
    "    \n",
    "    # Step 1: Zero the gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Step 2: Forward pass - compute predictions\n",
    "    outputs = simple_model(inputs)\n",
    "    \n",
    "    # Step 3: Compute the loss\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    # Step 4: Backward pass - compute gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 5: Update weights using computed gradients\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "print(\"\\nKey takeaway: Always call optimizer.zero_grad() BEFORE loss.backward()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kf82oz7vb8",
   "metadata": {},
   "source": [
    "## Breaking the Computation Graph with detach()\n",
    "\n",
    "The `detach()` method creates a new tensor that shares the same data but is detached from the computation graph. This is useful when you want to:\n",
    "- Use a tensor's value without tracking gradients through it\n",
    "- Prevent gradients from flowing back through certain parts of your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3ip4kyjw4zi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = tensor([2., 4., 6.], grad_fn=<MulBackward0>)\n",
      "y.grad_fn = <MulBackward0 object at 0x70d4db82cc10>\n",
      "y.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "# Demonstrating detach()\n",
    "\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "y = x * 2\n",
    "\n",
    "# y is connected to x in the computation graph\n",
    "print(f\"y = {y}\")\n",
    "print(f\"y.grad_fn = {y.grad_fn}\")\n",
    "print(f\"y.requires_grad = {y.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4ebcbaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y_detached = tensor([2., 4., 6.])\n",
      "y_detached.grad_fn = None\n",
      "y_detached.requires_grad = False\n"
     ]
    }
   ],
   "source": [
    "# detach() creates a new tensor with same values but no gradient connection\n",
    "y_detached = y.detach()\n",
    "print(f\"\\ny_detached = {y_detached}\")\n",
    "print(f\"y_detached.grad_fn = {y_detached.grad_fn}\")  # None - no computation history\n",
    "print(f\"y_detached.requires_grad = {y_detached.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "26042abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "z (from detached) = tensor([ 6., 12., 18.])\n",
      "z.requires_grad = False\n"
     ]
    }
   ],
   "source": [
    "# Use case: computing loss for logging without affecting gradients\n",
    "z = y_detached * 3  # This operation won't contribute to gradients through x\n",
    "print(f\"\\nz (from detached) = {z}\")\n",
    "print(f\"z.requires_grad = {z.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "10470407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After modifying y_detached[0] = 100:\n",
      "y = tensor([100.,   4.,   6.], grad_fn=<MulBackward0>)\n",
      "y_detached = tensor([100.,   4.,   6.])\n"
     ]
    }
   ],
   "source": [
    "# Important: detach() shares memory with original tensor\n",
    "y_detached[0] = 100\n",
    "print(f\"\\nAfter modifying y_detached[0] = 100:\")\n",
    "print(f\"y = {y}\")  # y is also modified because they share memory!\n",
    "print(f\"y_detached = {y_detached}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fc861882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With .detach().clone():\n",
      "y2 = tensor([2., 4.], grad_fn=<MulBackward0>)\n",
      "y2_copy = tensor([999.,   4.])\n"
     ]
    }
   ],
   "source": [
    "# If you need a completely independent copy, use .detach().clone()\n",
    "x2 = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "y2 = x2 * 2\n",
    "y2_copy = y2.detach().clone()  # Independent copy\n",
    "y2_copy[0] = 999\n",
    "\n",
    "print(f\"\\nWith .detach().clone():\")\n",
    "print(f\"y2 = {y2}\")  # Unchanged\n",
    "print(f\"y2_copy = {y2_copy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6jso059qh69",
   "metadata": {},
   "source": [
    "## Gradient Accumulation for Large Batch Training\n",
    "\n",
    "When you have limited GPU memory but want to train with a large effective batch size, you can accumulate gradients over multiple mini-batches before updating weights. This leverages PyTorch's default gradient accumulation behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "327fr6fgurm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Accumulation Training:\n",
      "\n",
      "Mini-batch 1: Loss = 1.6563\n",
      "Mini-batch 2: Loss = 0.8023\n",
      "Mini-batch 3: Loss = 4.7670\n",
      "Mini-batch 4: Loss = 1.3919\n",
      "\n",
      "Weights updated with accumulated gradients from all 4 mini-batches\n"
     ]
    }
   ],
   "source": [
    "# Gradient accumulation example\n",
    "# Goal: Train with effective batch size of 8, but only 2 samples fit in memory at a time\n",
    "\n",
    "model_ga = nn.Linear(10, 2)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model_ga.parameters(), lr=0.01)\n",
    "\n",
    "# Simulating 8 samples split into 4 mini-batches of 2\n",
    "all_inputs = torch.randn(8, 10)\n",
    "all_targets = torch.randn(8, 2)\n",
    "\n",
    "accumulation_steps = 4  # Number of mini-batches to accumulate before updating\n",
    "batch_size = 2\n",
    "\n",
    "print(\"Gradient Accumulation Training:\\n\")\n",
    "\n",
    "# Zero gradients once at the beginning\n",
    "optimizer.zero_grad()\n",
    "\n",
    "for i in range(accumulation_steps):\n",
    "    # Get mini-batch\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = start_idx + batch_size\n",
    "    inputs = all_inputs[start_idx:end_idx]\n",
    "    targets = all_targets[start_idx:end_idx]\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model_ga(inputs)\n",
    "    \n",
    "    # Scale loss to account for accumulation (average over all mini-batches)\n",
    "    loss = criterion(outputs, targets) / accumulation_steps\n",
    "    \n",
    "    # Backward pass - gradients are ACCUMULATED (not replaced)\n",
    "    loss.backward()\n",
    "    \n",
    "    print(f\"Mini-batch {i+1}: Loss = {loss.item() * accumulation_steps:.4f}\")\n",
    "\n",
    "# Update weights after accumulating all gradients\n",
    "optimizer.step()\n",
    "\n",
    "# Zero gradients for next iteration\n",
    "optimizer.zero_grad()\n",
    "\n",
    "print(\"\\nWeights updated with accumulated gradients from all 4 mini-batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j2v73khgxip",
   "metadata": {},
   "source": [
    "## retain_graph: Multiple Backward Passes\n",
    "\n",
    "By default, PyTorch frees the computation graph after `.backward()` to save memory. If you need to call backward multiple times on the same graph, use `retain_graph=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4sss6jkftcx",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After first backward: x.grad = tensor([2., 4.])\n"
     ]
    }
   ],
   "source": [
    "# Demonstrating retain_graph\n",
    "\n",
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "y = x ** 2\n",
    "z = y.sum()\n",
    "\n",
    "# First backward - need retain_graph if we want to call backward again\n",
    "z.backward(retain_graph=True)\n",
    "print(f\"After first backward: x.grad = {x.grad}\")\n",
    "\n",
    "# Without retain_graph=True, this would cause an error:\n",
    "# \"RuntimeError: Trying to backward through the graph a second time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9a8d0efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After second backward: x.grad = tensor([4., 8.])\n"
     ]
    }
   ],
   "source": [
    "# Second backward on the same graph\n",
    "z.backward(retain_graph=True)\n",
    "print(f\"After second backward: x.grad = {x.grad}\")  # Gradients accumulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "11c0a7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After third backward (reset first): x.grad = tensor([2., 4.])\n",
      "Error: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.\n"
     ]
    }
   ],
   "source": [
    "# Third backward - if we don't need the graph anymore, don't retain it\n",
    "x.grad.zero_()  # Reset gradients first\n",
    "z.backward()  # retain_graph=False by default\n",
    "print(f\"After third backward (reset first): x.grad = {x.grad}\")\n",
    "\n",
    "# Now the graph is freed, calling backward again would error:\n",
    "try:\n",
    "    z.backward()\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jr4qaec3v3",
   "metadata": {},
   "source": [
    "## Higher-Order Gradients (Gradients of Gradients)\n",
    "\n",
    "Using `create_graph=True` preserves the computation graph of the gradients themselves, allowing you to compute higher-order derivatives. This is useful for:\n",
    "- Meta-learning (MAML)\n",
    "- Some regularization techniques (e.g., gradient penalty in WGAN-GP)\n",
    "- Hessian computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "76zekxo9qg5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x) = x^3 at x=2: 8.0\n",
      "f'(x) = 3x^2 at x=2: 12.0\n"
     ]
    }
   ],
   "source": [
    "# Computing second-order derivatives\n",
    "\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "\n",
    "# Function: f(x) = x^3\n",
    "# First derivative: f'(x) = 3x^2\n",
    "# Second derivative: f''(x) = 6x\n",
    "\n",
    "y = x ** 3\n",
    "\n",
    "# Compute first derivative with create_graph=True to track the gradient computation\n",
    "first_derivative = torch.autograd.grad(outputs=y, inputs=x, create_graph=True)[0]\n",
    "print(f\"f(x) = x^3 at x=2: {y.item()}\")\n",
    "print(f\"f'(x) = 3x^2 at x=2: {first_derivative.item()}\")  # Should be 3*4 = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6c9b5893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f''(x) = 6x at x=2: 12.0\n"
     ]
    }
   ],
   "source": [
    "# Compute second derivative (gradient of the gradient)\n",
    "second_derivative = torch.autograd.grad(first_derivative, x)[0]\n",
    "print(f\"f''(x) = 6x at x=2: {second_derivative.item()}\")  # Should be 6*2 = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0e580a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 0.6957\n",
      "Gradient penalty: 0.0926\n"
     ]
    }
   ],
   "source": [
    "# Practical example: Gradient penalty (used in WGAN-GP)\n",
    "\n",
    "# Simple network\n",
    "net = nn.Linear(5, 1)\n",
    "x_input = torch.randn(1, 5, requires_grad=True)\n",
    "\n",
    "# Forward pass\n",
    "output = net(x_input)\n",
    "\n",
    "# Compute gradients of output w.r.t. input (with create_graph to allow further differentiation)\n",
    "gradients = torch.autograd.grad(\n",
    "    outputs=output,\n",
    "    inputs=x_input,\n",
    "    create_graph=True,  # Needed to compute gradient of the gradient\n",
    "    retain_graph=True\n",
    ")[0]\n",
    "\n",
    "# Gradient penalty: (||gradient|| - 1)^2\n",
    "gradient_penalty = ((gradients.norm(2) - 1) ** 2)\n",
    "print(f\"Gradient norm: {gradients.norm(2).item():.4f}\")\n",
    "print(f\"Gradient penalty: {gradient_penalty.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0a5876dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network weight gradients computed: True\n"
     ]
    }
   ],
   "source": [
    "# Now we can backprop through the penalty\n",
    "gradient_penalty.backward()\n",
    "print(f\"Network weight gradients computed: {net.weight.grad is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96j7xlfk255",
   "metadata": {},
   "source": [
    "## Common Pitfalls and Gotchas\n",
    "\n",
    "### 1. In-place Operations Break Gradients\n",
    "\n",
    "In-place operations (operations that modify tensors in place, denoted by `_` suffix) can break the computation graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "gzp6f0fi98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad = tensor([2., 2.])\n",
      "\n",
      "In-place operations are fine on leaf tensors that don't need gradients:\n",
      "a = tensor([11., 12.])\n"
     ]
    }
   ],
   "source": [
    "# In-place operations can cause problems\n",
    "\n",
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "y = x * 2\n",
    "\n",
    "# BAD: In-place modification of y (which is part of the computation graph)\n",
    "# y.add_(1)  # This would cause: RuntimeError when calling backward\n",
    "\n",
    "# GOOD: Out-of-place operation instead\n",
    "y = y + 1  # Creates a new tensor\n",
    "\n",
    "z = y.sum()\n",
    "z.backward()\n",
    "print(f\"x.grad = {x.grad}\")  # Works fine\n",
    "\n",
    "# List of common in-place operations to avoid on tensors in computation graph:\n",
    "# add_(), sub_(), mul_(), div_(), zero_(), fill_(), etc.\n",
    "\n",
    "print(\"\\nIn-place operations are fine on leaf tensors that don't need gradients:\")\n",
    "a = torch.tensor([1.0, 2.0])\n",
    "a.add_(10)  # This is fine - 'a' doesn't require gradients\n",
    "print(f\"a = {a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bpdlw0ar9p6",
   "metadata": {},
   "source": [
    "### 2. Leaf Tensors and Non-Leaf Tensors\n",
    "\n",
    "Only leaf tensors (tensors created directly, not as a result of operations) retain their gradients by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "dbllooagyg8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is leaf: True\n"
     ]
    }
   ],
   "source": [
    "# Understanding leaf vs non-leaf tensors\n",
    "\n",
    "# Leaf tensor: created directly\n",
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "print(f\"x is leaf: {x.is_leaf}\")  # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f9947e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y is leaf: False\n"
     ]
    }
   ],
   "source": [
    "# Non-leaf tensor: result of an operation\n",
    "y = x * 2\n",
    "print(f\"y is leaf: {y.is_leaf}\")  # False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "47e02477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x.grad = tensor([2., 2.])\n",
      "y.grad = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6055/2937259444.py:5: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /pytorch/build/aten/src/ATen/core/TensorBody.h:489.)\n",
      "  print(f\"y.grad = {y.grad}\")  # None by default - non-leaf tensors don't retain gradients\n"
     ]
    }
   ],
   "source": [
    "z = y.sum()\n",
    "z.backward()\n",
    "\n",
    "print(f\"\\nx.grad = {x.grad}\")  # Has gradient - it's a leaf\n",
    "print(f\"y.grad = {y.grad}\")  # None by default - non-leaf tensors don't retain gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b44201aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With retain_grad():\n",
      "x2.grad = tensor([2., 2.])\n",
      "y2.grad = tensor([1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# If you need gradients for non-leaf tensors, use retain_grad()\n",
    "x2 = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "y2 = x2 * 2\n",
    "y2.retain_grad()  # Tell PyTorch to keep gradient for this non-leaf tensor\n",
    "\n",
    "z2 = y2.sum()\n",
    "z2.backward()\n",
    "\n",
    "print(f\"\\nWith retain_grad():\")\n",
    "print(f\"x2.grad = {x2.grad}\")\n",
    "print(f\"y2.grad = {y2.grad}\")  # Now it has a gradient!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zcr0zpo9tma",
   "metadata": {},
   "source": [
    "### 3. Converting Tensors with Gradients to NumPy\n",
    "\n",
    "You cannot directly convert a tensor that requires gradients to NumPy. You must detach it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "tqw7o7fg9ln",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted to numpy: [1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "\n",
    "# BAD: This will raise an error\n",
    "# x_numpy = x.numpy()  # RuntimeError: Can't call numpy() on Tensor that requires grad\n",
    "\n",
    "# GOOD: Detach first, then convert\n",
    "x_numpy = x.detach().numpy()\n",
    "print(f\"Converted to numpy: {x_numpy}\")\n",
    "\n",
    "# Or use .cpu().detach().numpy() for GPU tensors\n",
    "# x_numpy = x.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hdp9miewigg",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Key Autograd Concepts\n",
    "\n",
    "| Concept | Description | When to Use |\n",
    "|---------|-------------|-------------|\n",
    "| `requires_grad=True` | Enable gradient tracking | Learnable parameters |\n",
    "| `backward()` | Compute gradients | After computing loss |\n",
    "| `zero_grad()` | Reset gradients | Before each backward pass |\n",
    "| `torch.no_grad()` | Disable gradient tracking | Inference/evaluation |\n",
    "| `detach()` | Break computation graph | Get tensor value without gradients |\n",
    "| `retain_graph=True` | Keep graph after backward | Multiple backward passes |\n",
    "| `create_graph=True` | Track gradient computation | Higher-order derivatives |\n",
    "\n",
    "### Training Loop Checklist\n",
    "\n",
    "```python\n",
    "optimizer.zero_grad()    # 1. Clear old gradients\n",
    "output = model(input)    # 2. Forward pass\n",
    "loss = criterion(output, target)  # 3. Compute loss\n",
    "loss.backward()          # 4. Compute gradients\n",
    "optimizer.step()         # 5. Update weights\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2034b075",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-cookbook-for-noobs (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb2fb3c",
   "metadata": {},
   "source": [
    "# PyTorch Tensors: The Foundation of Deep Learning\n",
    "\n",
    "## What is a Tensor?\n",
    "\n",
    "A **tensor** is a multi-dimensional array, similar to NumPy's ndarray, but with two key advantages:\n",
    "1. **GPU acceleration** - Tensors can run on GPUs for faster computation\n",
    "2. **Automatic differentiation** - PyTorch tracks operations for computing gradients\n",
    "\n",
    "### Tensor Dimensions\n",
    "- **0D tensor**: Scalar (single number)\n",
    "- **1D tensor**: Vector (array)\n",
    "- **2D tensor**: Matrix (table)\n",
    "- **3D+ tensor**: Higher-dimensional arrays (e.g., images, videos)\n",
    "\n",
    "> Reference: https://docs.pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f92cde0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1+cu118\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Import the essential libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Check PyTorch version and GPU availability\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fceadf8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Creating Tensors\n",
    "\n",
    "There are multiple ways to create tensors in PyTorch. Let's explore the most common methods.\n",
    "\n",
    "### From Python Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ffc5ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n",
      "Shape: torch.Size([2, 2])\n",
      "Data type: torch.int64\n",
      "Device: cpu\n",
      "Dimensions: 2\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Creating a tensor directly from Python data (list, tuple, etc.)\n",
    "# =============================================================================\n",
    "\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "print(\"x_data:\")\n",
    "print(x_data)\n",
    "print(f\"\\nShape: {x_data.shape}\")        # torch.Size([2, 2])\n",
    "print(f\"Data type: {x_data.dtype}\")      # torch.int64 (inferred from data)\n",
    "print(f\"Device: {x_data.device}\")        # cpu (default)\n",
    "print(f\"Dimensions: {x_data.ndim}\")      # 2 (it's a 2D tensor/matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yb6tmavccdi",
   "metadata": {},
   "source": [
    "### From NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0d54695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array:\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "Shape: (2, 2), dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Creating a tensor from NumPy array\n",
    "# =============================================================================\n",
    "\n",
    "data = [[1, 2], [3, 4]]\n",
    "\n",
    "np_array = np.array(data)\n",
    "\n",
    "print(\"NumPy array:\")\n",
    "print(np_array)\n",
    "print(f\"Shape: {np_array.shape}, dtype: {np_array.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24e62e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensor from NumPy:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "Shape: torch.Size([2, 2]), dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Convert NumPy array to PyTorch tensor\n",
    "# Note: This shares memory with the original array by default!\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(\"\\nTensor from NumPy:\")\n",
    "print(x_np)\n",
    "print(f\"Shape: {x_np.shape}, dtype: {x_np.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b028bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_array[0,0] = \n",
      " [[999   2]\n",
      " [  3   4]]\n",
      "\n",
      "x_np[0,0] = \n",
      " tensor([[999,   2],\n",
      "        [  3,   4]])\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: They share memory - modifying one affects the other!\n",
    "np_array[0, 0] = 999\n",
    "print(f\"np_array[0,0] = \\n {np_array}\")\n",
    "print(f\"\\nx_np[0,0] = \\n {x_np}\")  # Also changed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5ef1ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset for later examples\n",
    "np_array[0, 0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "haziac2auni",
   "metadata": {},
   "source": [
    "### From Another Tensor (Retaining Properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3d624af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original tensor: torch.Size([2, 2]), dtype: torch.int64\n",
      "zeros_like(x_data):\n",
      "tensor([[0, 0],\n",
      "        [0, 0]])\n",
      "Shape: torch.Size([2, 2]), dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Creating tensors that inherit shape/dtype from existing tensors\n",
    "# =============================================================================\n",
    "\n",
    "# The \"_like\" functions are useful for creating tensors with the same\n",
    "# shape as another tensor (e.g., for initializing gradients, masks, etc.)\n",
    "\n",
    "# zeros_like: Creates a tensor of zeros with the same shape and dtype\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(f\"Shape of original tensor: {x_data.shape}, dtype: {x_data.dtype}\")\n",
    "x_zeros = torch.zeros_like(x_data)\n",
    "print(\"zeros_like(x_data):\")\n",
    "print(x_zeros)\n",
    "print(f\"Shape: {x_zeros.shape}, dtype: {x_zeros.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1610acf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ones_like(x_data):\n",
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "Shape: torch.Size([2, 2]), dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "# ones_like: Creates a tensor of ones\n",
    "x_ones = torch.ones_like(x_data)\n",
    "print(\"\\nones_like(x_data):\")\n",
    "print(x_ones)\n",
    "print(f\"Shape: {x_ones.shape}, dtype: {x_ones.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83f9a78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rand_like(x_data, dtype=float32):\n",
      "tensor([[0.3322, 0.8717],\n",
      "        [0.5361, 0.3260]])\n",
      "dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# rand_like: Creates a tensor with random values [0, 1)\n",
    "# You can override the dtype if needed\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float32)\n",
    "print(\"\\nrand_like(x_data, dtype=float32):\")\n",
    "print(x_rand)\n",
    "print(f\"dtype: {x_rand.dtype}\")  # Now float32 instead of int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fhk8bmvgs18",
   "metadata": {},
   "source": [
    "### With Random or Constant Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a683db80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.rand(2, 3):\n",
      "tensor([[0.6476, 0.8598, 0.9326],\n",
      "        [0.1951, 0.6621, 0.6096]])\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Creating tensors with specific values\n",
    "# =============================================================================\n",
    "\n",
    "shape = (2, 3)\n",
    "\n",
    "# Random values from uniform distribution [0, 1) using rand\n",
    "rand_tensor = torch.rand(shape)\n",
    "print(f\"torch.rand{shape}:\")\n",
    "print(rand_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e46cb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.randn(2, 3) (normal distribution):\n",
      "tensor([[-0.3812, -0.3822,  1.3878],\n",
      "        [-0.7554, -1.2169, -0.0414]])\n"
     ]
    }
   ],
   "source": [
    "# Random values from standard normal distribution (mean=0, std=1) using randn\n",
    "randn_tensor = torch.randn(shape)\n",
    "print(f\"\\ntorch.randn{shape} (normal distribution):\")\n",
    "print(randn_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db141268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.ones (2, 3):\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# All ones\n",
    "ones_tensor = torch.ones(shape)\n",
    "print(f\"\\ntorch.ones{shape}:\")\n",
    "print(ones_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52e0a0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.zeros(2, 3):\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# All zeros\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "print(f\"\\ntorch.zeros{shape}:\")\n",
    "print(zeros_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0eefbb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.full(2, 3), fill_value=7):\n",
      "tensor([[7, 7, 7],\n",
      "        [7, 7, 7]])\n"
     ]
    }
   ],
   "source": [
    "# All same value\n",
    "full_tensor = torch.full(shape, fill_value=7)\n",
    "print(f\"\\ntorch.full{shape}, fill_value=7):\")\n",
    "print(full_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hmt5pmiri1j",
   "metadata": {},
   "source": [
    "### More Creation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69qn760451e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.arange(0, 10, 2):\n",
      "tensor([0, 2, 4, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Additional useful tensor creation functions\n",
    "# =============================================================================\n",
    "\n",
    "# arange: Like Python's range(), creates evenly spaced values\n",
    "arange_tensor = torch.arange(start=0, end=10, step=2)\n",
    "print(\"torch.arange(0, 10, 2):\")\n",
    "print(arange_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "319fe933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.linspace(0, 1, steps=5):\n",
      "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "# linspace: Creates n evenly spaced values between start and end (inclusive)\n",
    "linspace_tensor = torch.linspace(start=0, end=1, steps=5)\n",
    "print(\"\\ntorch.linspace(0, 1, steps=5):\")\n",
    "print(linspace_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "380bc97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.eye(3):\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# eye: Identity matrix (1s on diagonal, 0s elsewhere)\n",
    "eye_tensor = torch.eye(3)\n",
    "print(\"\\ntorch.eye(3):\")\n",
    "print(eye_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f23e1ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.empty(2, 3) - contains uninitialized values:\n",
      "tensor([[3.1410e-12, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "# empty: Uninitialized tensor (faster, but contains garbage values)\n",
    "# Use when you'll immediately overwrite all values\n",
    "empty_tensor = torch.empty(2, 3)\n",
    "print(\"\\ntorch.empty(2, 3) - contains uninitialized values:\")\n",
    "print(empty_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54348321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.randint(0, 10, size=(2, 3)):\n",
      "tensor([[5, 3, 4],\n",
      "        [6, 6, 1]])\n"
     ]
    }
   ],
   "source": [
    "# randint: Random integers in range [low, high)\n",
    "randint_tensor = torch.randint(low=0, high=10, size=(2, 3))\n",
    "print(\"\\ntorch.randint(0, 10, size=(2, 3)):\")\n",
    "print(randint_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ry37kcgzuh",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tensor Data Types (dtypes)\n",
    "\n",
    "PyTorch tensors have specific data types that affect precision, memory usage, and GPU compatibility.\n",
    "\n",
    "### Common Data Types\n",
    "| dtype | Description | Use Case |\n",
    "|-------|-------------|----------|\n",
    "| `torch.float32` | 32-bit float (default) | Most neural network operations |\n",
    "| `torch.float64` | 64-bit float | High precision calculations |\n",
    "| `torch.float16` | 16-bit float | GPU memory optimization |\n",
    "| `torch.int64` | 64-bit integer | Indices, labels |\n",
    "| `torch.int32` | 32-bit integer | Smaller indices |\n",
    "| `torch.bool` | Boolean | Masks, conditions |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "rvqunema1jn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float_tensor: tensor([1., 2., 3.]), dtype: torch.float32\n",
      "int_tensor: tensor([1, 2, 3]), dtype: torch.int64\n",
      "bool_tensor: tensor([ True, False,  True]), dtype: torch.bool\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Specifying and converting data types\n",
    "# =============================================================================\n",
    "\n",
    "# Specify dtype at creation time\n",
    "float_tensor = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)\n",
    "int_tensor = torch.tensor([1, 2, 3], dtype=torch.int64)\n",
    "bool_tensor = torch.tensor([True, False, True], dtype=torch.bool)\n",
    "\n",
    "print(f\"float_tensor: {float_tensor}, dtype: {float_tensor.dtype}\")\n",
    "print(f\"int_tensor: {int_tensor}, dtype: {int_tensor.dtype}\")\n",
    "print(f\"bool_tensor: {bool_tensor}, dtype: {bool_tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce1f0a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original: tensor([1, 2, 3]), dtype: torch.int64\n",
      "to(float32): tensor([1., 2., 3.]), dtype: torch.float32\n",
      "to(float64): tensor([1., 2., 3.], dtype=torch.float64), dtype: torch.float64\n"
     ]
    }
   ],
   "source": [
    "# Convert between dtypes using .to() method\n",
    "x = torch.tensor([1, 2, 3])\n",
    "print(f\"\\nOriginal: {x}, dtype: {x.dtype}\")\n",
    "\n",
    "x_float = x.to(torch.float32)\n",
    "print(f\"to(float32): {x_float}, dtype: {x_float.dtype}\")\n",
    "\n",
    "x_double = x.to(torch.float64)\n",
    "print(f\"to(float64): {x_double}, dtype: {x_double.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "930ef9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shortcut methods:\n",
      ".float(): tensor([1., 2., 3.]), dtype: torch.float32\n",
      ".long(): tensor([1, 2, 3]), dtype: torch.int64\n",
      ".double(): tensor([1., 2., 3.], dtype=torch.float64), dtype: torch.float64\n",
      ".bool(): tensor([True, True, True]), dtype: torch.bool\n"
     ]
    }
   ],
   "source": [
    "# Shortcut methods for common conversions\n",
    "print(\"\\nShortcut methods:\")\n",
    "print(f\".float(): {x.float()}, dtype: {x.float().dtype}\")\n",
    "print(f\".long(): {x.long()}, dtype: {x.long().dtype}\")\n",
    "print(f\".double(): {x.double()}, dtype: {x.double().dtype}\")\n",
    "print(f\".bool(): {x.bool()}, dtype: {x.bool().dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tk2hmkicbe9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tensor Attributes\n",
    "\n",
    "Every tensor has important attributes that describe its properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "zurf1uh9gdk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Attributes:\n",
      "----------------------------------------\n",
      "Shape:        torch.Size([3, 4, 5])\n",
      "Size:         torch.Size([3, 4, 5])\n",
      "Dimensions:   3\n",
      "Num elements: 60\n",
      "Data type:    torch.float32\n",
      "Device:       cpu\n",
      "Contiguous:   True\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Key tensor attributes\n",
    "# =============================================================================\n",
    "\n",
    "tensor = torch.randn(3, 4, 5)\n",
    "\n",
    "print(\"Tensor Attributes:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Shape:        {tensor.shape}\")        # Size of each dimension\n",
    "print(f\"Size:         {tensor.size()}\")       # Same as shape (method)\n",
    "print(f\"Dimensions:   {tensor.ndim}\")         # Number of dimensions\n",
    "print(f\"Num elements: {tensor.numel()}\")      # Total number of elements\n",
    "print(f\"Data type:    {tensor.dtype}\")        # Data type\n",
    "print(f\"Device:       {tensor.device}\")       # cpu or cuda\n",
    "print(f\"Contiguous:   {tensor.is_contiguous()}\")  # Memory layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d247a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimension sizes:\n",
      "  Dim 0: 3\n",
      "  Dim 1: 4\n",
      "  Dim 2: 5\n"
     ]
    }
   ],
   "source": [
    "# Individual dimension sizes\n",
    "print(f\"\\nDimension sizes:\")\n",
    "for i in range(tensor.ndim):\n",
    "    print(f\"  Dim {i}: {tensor.size(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce26ad77",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tensor Operations\n",
    "\n",
    "PyTorch provides a comprehensive set of operations for tensors. Full list: https://docs.pytorch.org/docs/stable/torch.html\n",
    "\n",
    "### Moving Tensors to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d82c2caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original device: cpu\n",
      "CUDA not available - tensors stay on CPU\n",
      "Tip: GPU operations are much faster for large tensors!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Moving tensors between devices (CPU <-> GPU)\n",
    "# =============================================================================\n",
    "\n",
    "tensor = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
    "print(f\"Original device: {tensor.device}\")\n",
    "\n",
    "# Check if CUDA (GPU) is available\n",
    "if torch.cuda.is_available():\n",
    "    # Move to GPU\n",
    "    tensor_gpu = tensor.to('cuda')\n",
    "    print(f\"After .to('cuda'): {tensor_gpu.device}\")\n",
    "    \n",
    "    # Alternative: specify GPU index\n",
    "    # tensor_gpu = tensor.to('cuda:0')\n",
    "    \n",
    "    # Move back to CPU\n",
    "    tensor_cpu = tensor_gpu.to('cpu')\n",
    "    print(f\"After .to('cpu'): {tensor_cpu.device}\")\n",
    "    \n",
    "    # Shortcut methods\n",
    "    # tensor.cuda()  # Move to default GPU\n",
    "    # tensor.cpu()   # Move to CPU\n",
    "else:\n",
    "    print(\"CUDA not available - tensors stay on CPU\")\n",
    "    print(\"Tip: GPU operations are much faster for large tensors!\")\n",
    "\n",
    "# IMPORTANT: Operations between tensors must be on the same device\n",
    "# tensor_cpu + tensor_gpu  # This would raise an error!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bohr6ncz4kh",
   "metadata": {},
   "source": [
    "### Indexing and Slicing\n",
    "\n",
    "Tensor indexing works like NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "de4087ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor x (3x4):\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Indexing and slicing tensors\n",
    "# =============================================================================\n",
    "\n",
    "x = torch.tensor([[1, 2, 3, 4],\n",
    "                  [5, 6, 7, 8],\n",
    "                  [9, 10, 11, 12]])\n",
    "print(\"Original tensor x (3x4):\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d75b8dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x[0] (first row): tensor([1, 2, 3, 4])\n",
      "x[0, 0] (first element): 1\n",
      "x[-1] (last row): tensor([ 9, 10, 11, 12])\n"
     ]
    }
   ],
   "source": [
    "# Basic indexing\n",
    "print(f\"\\nx[0] (first row): {x[0]}\")\n",
    "print(f\"x[0, 0] (first element): {x[0, 0]}\")\n",
    "print(f\"x[-1] (last row): {x[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "72972d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x[:, 0] (first column): tensor([1, 5, 9])\n",
      "x[0:2, 1:3] (rows 0-1, cols 1-2):\n",
      "tensor([[2, 3],\n",
      "        [6, 7]])\n",
      "x[::2] (every other row):\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 9, 10, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "# Slicing: [start:end:step] - end is exclusive\n",
    "print(f\"\\nx[:, 0] (first column): {x[:, 0]}\")\n",
    "print(f\"x[0:2, 1:3] (rows 0-1, cols 1-2):\\n{x[0:2, 1:3]}\")\n",
    "print(f\"x[::2] (every other row):\\n{x[::2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0860af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x[..., -1] (last column): tensor([ 4,  8, 12])\n"
     ]
    }
   ],
   "source": [
    "# Using ... (ellipsis) for remaining dimensions\n",
    "print(f\"\\nx[..., -1] (last column): {x[..., -1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "111e4d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor x:\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Modifying tensors using indexing\n",
    "# =============================================================================\n",
    "\n",
    "x = torch.tensor([[1, 2, 3, 4],\n",
    "                  [5, 6, 7, 8],\n",
    "                  [9, 10, 11, 12]])\n",
    "\n",
    "print(\"Original tensor x:\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fbdca02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After x[:, 1] = 0:\n",
      "tensor([[ 1,  0,  3,  4],\n",
      "        [ 5,  0,  7,  8],\n",
      "        [ 9,  0, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "# Set entire column to a single value\n",
    "x[:, 1] = 0\n",
    "print(\"After x[:, 1] = 0:\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cdc3d323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After x[x > 8] = 99:\n",
      "tensor([[ 1,  0,  3,  4],\n",
      "        [ 5,  0,  7,  8],\n",
      "        [99,  0, 99, 99]])\n"
     ]
    }
   ],
   "source": [
    "# Set values using boolean mask\n",
    "x[x > 8] = 99\n",
    "print(\"\\nAfter x[x > 8] = 99:\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2o1pgbaumwe",
   "metadata": {},
   "source": [
    "### Joining Tensors\n",
    "\n",
    "`cat()` concatenates along an existing dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1838a075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (shape torch.Size([2, 2])):\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# torch.cat - Concatenate along existing dimension\n",
    "# =============================================================================\n",
    "\n",
    "x = torch.tensor([[1, 2], [3, 4]])\n",
    "print(f\"x (shape {x.shape}):\\n{x}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5e306b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat([x, x, x], dim=0) - shape torch.Size([6, 2]):\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [1, 2],\n",
      "        [3, 4],\n",
      "        [1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# dim=0: Concatenate along rows (stack vertically)\n",
    "t1 = torch.cat([x, x, x], dim=0)\n",
    "print(f\"cat([x, x, x], dim=0) - shape {t1.shape}:\")\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ddeaa46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cat([x, x], dim=1) - shape torch.Size([2, 4]):\n",
      "tensor([[1, 2, 1, 2],\n",
      "        [3, 4, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# dim=1: Concatenate along columns (stack horizontally)\n",
    "t2 = torch.cat([x, x], dim=1)\n",
    "print(f\"\\ncat([x, x], dim=1) - shape {t2.shape}:\")\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88402c99",
   "metadata": {},
   "source": [
    " `stack()` creates a new dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "51e03dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (shape torch.Size([2, 2])):\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# torch.stack - Stack tensors along a NEW dimension\n",
    "# =============================================================================\n",
    "\n",
    "# stack() adds a new dimension, unlike cat() which extends an existing one\n",
    "\n",
    "x = torch.tensor([[1, 2], [3, 4]])  # Shape: (2, 2)\n",
    "print(f\"x (shape {x.shape}):\\n{x}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a9142ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack([x, x], dim=0) - shape torch.Size([2, 2, 2])\n",
      "It becomes: 2 matrices of shape (2, 2)\n",
      "\n",
      "t3:\n",
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[1, 2],\n",
      "         [3, 4]]])\n"
     ]
    }
   ],
   "source": [
    "# dim=0: New dimension at position 0\n",
    "# Shape: (2, 2) -> (2, 2, 2)\n",
    "t3 = torch.stack([x, x], dim=0)\n",
    "print(f\"stack([x, x], dim=0) - shape {t3.shape}\")\n",
    "print(f\"It becomes: 2 matrices of shape (2, 2)\\n\")\n",
    "print(\"t3:\")\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f088a89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack([x, x], dim=1) - shape torch.Size([2, 2, 2])\n",
      "\n",
      "t4:\n",
      "tensor([[[1, 2],\n",
      "         [1, 2]],\n",
      "\n",
      "        [[3, 4],\n",
      "         [3, 4]]])\n"
     ]
    }
   ],
   "source": [
    "# dim=1: New dimension at position 1\n",
    "# Shape: (2, 2) -> (2, 2, 2) but organized differently\n",
    "t4 = torch.stack([x, x], dim=1)\n",
    "print(f\"stack([x, x], dim=1) - shape {t4.shape}\")\n",
    "print(\"\\nt4:\")\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c0a2544f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack([x, x], dim=2) - shape torch.Size([2, 2, 2])\n",
      "\n",
      "t5:\n",
      "tensor([[[1, 1],\n",
      "         [2, 2]],\n",
      "\n",
      "        [[3, 3],\n",
      "         [4, 4]]])\n"
     ]
    }
   ],
   "source": [
    "# dim=2: New dimension at position 2\n",
    "t5 = torch.stack([x, x], dim=2)\n",
    "print(f\"stack([x, x], dim=2) - shape {t5.shape}\")\n",
    "print(\"\\nt5:\")\n",
    "print(t5)\n",
    "\n",
    "# Key difference from cat:\n",
    "# cat([x, x], dim=0).shape = (4, 2)  - extends existing dim\n",
    "# stack([x, x], dim=0).shape = (2, 2, 2)  - creates new dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ltqjhkovp",
   "metadata": {},
   "source": [
    "### Reshaping Tensors\n",
    "\n",
    "Reshaping allows you to change the dimensions of a tensor without changing its data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5bf66dcvttm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original x (shape torch.Size([12])): tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Reshaping operations\n",
    "# =============================================================================\n",
    "\n",
    "x = torch.arange(12)  # [0, 1, 2, ..., 11]\n",
    "print(f\"Original x (shape {x.shape}): {x}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "096a580b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.view(3, 4) - shape torch.Size([3, 4]):\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# view: Reshape tensor (must be contiguous in memory)\n",
    "# contiguouys means that the data is stored in a single, unbroken block of memory\n",
    "v = x.view(3, 4)\n",
    "print(f\"x.view(3, 4) - shape {v.shape}:\")\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "22a868bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x.reshape(2, 6) - shape torch.Size([2, 6]):\n",
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# reshape: Like view, but works on non-contiguous tensors (may copy data)\n",
    "r = x.reshape(2, 6)\n",
    "print(f\"\\nx.reshape(2, 6) - shape {r.shape}:\")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "635b2106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x.view(4, -1) - shape torch.Size([4, 3])\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# Use -1 to infer dimension automatically\n",
    "auto = x.view(4, -1)  # -1 becomes 3 (12/4=3)\n",
    "print(f\"\\nx.view(4, -1) - shape {auto.shape}\")\n",
    "print(auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b3b390a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original v:\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "\n",
      "v.flatten() - shape torch.Size([12]): tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n"
     ]
    }
   ],
   "source": [
    "# flatten: Collapse all dimensions into 1D\n",
    "print(\"\\nOriginal v:\"\n",
    "      f\"\\n{v}\")\n",
    "f = v.flatten()\n",
    "print(f\"\\nv.flatten() - shape {f.shape}: {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c4b01469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original y (shape torch.Size([2, 1, 3, 1])):\n",
      "tensor([[[[0.],\n",
      "          [0.],\n",
      "          [0.]]],\n",
      "\n",
      "\n",
      "        [[[0.],\n",
      "          [0.],\n",
      "          [0.]]]])\n",
      "\n",
      "After squeeze(): torch.Size([2, 3])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "Only remove last dim using squeeze(-1):\n",
      "torch.Size([2, 1, 3])\n",
      "tensor([[[0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "# squeeze: Remove dimensions of size 1\n",
    "y = torch.zeros(2, 1, 3, 1)\n",
    "print(f\"\\nOriginal y (shape {y.shape}):\")\n",
    "print(y)\n",
    "squeezed = y.squeeze()\n",
    "print(f\"\\nAfter squeeze(): {squeezed.shape}\")\n",
    "print(squeezed)\n",
    "print(\"\\nOnly remove last dim using squeeze(-1):\")\n",
    "print(y.squeeze(-1).shape)\n",
    "print(y.squeeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b83f3efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original z shape: torch.Size([3])\n",
      "z: tensor([1, 2, 3])\n",
      "\n",
      "z.unsqueeze(0) shape: torch.Size([1, 3])\n",
      "z.unsqueeze(0): \n",
      " tensor([[1, 2, 3]]) \n",
      "\n",
      "z.unsqueeze(1) shape: torch.Size([3, 1])\n",
      "z.unsqueeze(1): \n",
      " tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n"
     ]
    }
   ],
   "source": [
    "# unsqueeze: Add a dimension of size 1\n",
    "z = torch.tensor([1, 2, 3])\n",
    "print(f\"\\nOriginal z shape: {z.shape}\")\n",
    "print(f\"z: {z}\")\n",
    "print(f\"\\nz.unsqueeze(0) shape: {z.unsqueeze(0).shape}\")  # Add batch dim\n",
    "print(\"z.unsqueeze(0): \\n\", z.unsqueeze(0), \"\\n\")\n",
    "print(f\"z.unsqueeze(1) shape: {z.unsqueeze(1).shape}\")  # Add column dim\n",
    "print(\"z.unsqueeze(1): \\n\", z.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "nonwqc6g9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Transpose and permute\n",
    "# =============================================================================\n",
    "\n",
    "x = torch.randn(2, 3, 4)\n",
    "print(f\"Original shape: {x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5890717c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transpose(0, 2): torch.Size([4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# transpose: Swap two specific dimensions\n",
    "t = x.transpose(0, 2)  # Swap dims 0 and 2\n",
    "print(f\"transpose(0, 2): {t.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "94c8e736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "permute(2, 0, 1): torch.Size([4, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# permute: Reorder all dimensions at once\n",
    "p = x.permute(2, 0, 1)  # New order: dim2, dim0, dim1\n",
    "print(f\"permute(2, 0, 1): {p.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b3adeb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matrix shape: torch.Size([2, 3])\n",
      "Matrix.T shape: torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# For 2D tensors, .T is a shortcut for transpose\n",
    "m = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(f\"\\nMatrix shape: {m.shape}\")\n",
    "print(f\"Matrix.T shape: {m.T.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xds7ufl15y8",
   "metadata": {},
   "source": [
    "### Reduction Operations\n",
    "\n",
    "These operations reduce tensor dimensions by aggregating values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "oawrvt2sa7q",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (shape torch.Size([2, 3])):\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Reduction operations: sum, mean, max, min, etc.\n",
    "# =============================================================================\n",
    "\n",
    "x = torch.tensor([[1., 2., 3.],\n",
    "                  [4., 5., 6.]])\n",
    "print(f\"x (shape {x.shape}):\\n{x}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ddca66a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum:  21.0\n",
      "mean: 3.5\n",
      "max:  6.0\n",
      "min:  1.0\n",
      "std:  1.8708\n"
     ]
    }
   ],
   "source": [
    "# Reduce entire tensor to single value\n",
    "print(f\"sum:  {x.sum()}\")\n",
    "print(f\"mean: {x.mean()}\")\n",
    "print(f\"max:  {x.max()}\")\n",
    "print(f\"min:  {x.min()}\")\n",
    "print(f\"std:  {x.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4c390166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sum(dim=0) - sum each column: tensor([5., 7., 9.])\n",
      "sum(dim=1) - sum each row:    tensor([ 6., 15.])\n",
      "mean(dim=1) - mean each row:  tensor([2., 5.])\n"
     ]
    }
   ],
   "source": [
    "# Reduce along specific dimension\n",
    "print(f\"\\nsum(dim=0) - sum each column: {x.sum(dim=0)}\")\n",
    "print(f\"sum(dim=1) - sum each row:    {x.sum(dim=1)}\")\n",
    "print(f\"mean(dim=1) - mean each row:  {x.mean(dim=1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64a0a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original x (shape torch.Size([2, 3])):\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "\n",
      "max(dim=1):\n",
      "  values:  tensor([3., 6.])\n",
      "  indices: tensor([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original x (shape {x.shape}):\\n{x}\\n\")\n",
    "\n",
    "# max/min return both values and indices\n",
    "values, indices = x.max(dim=1)\n",
    "print(f\"\\nmax(dim=1):\")\n",
    "print(f\"  values:  {values}\")\n",
    "print(f\"  indices: {indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76678af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original x (shape torch.Size([2, 3])):\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "\n",
      "argmax (flattened): 5\n",
      "argmax(dim=0):      tensor([1, 1, 1])\n",
      "argmax(dim=1):      tensor([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original x (shape {x.shape}):\\n{x}\\n\")\n",
    "\n",
    "# argmax/argmin return only indices\n",
    "print(f\"\\nargmax (flattened): {x.argmax()}\")  # 5 - Max value 6 is at index 5\n",
    "\n",
    "print(f\"argmax(dim=0):      {x.argmax(dim=0)}\")  # Index along dim 0 - tensor([1, 1, 1])\n",
    "# argmax(dim=0) = [1, 1, 1]\n",
    "# - Compares rows for each column:\n",
    "# - Col 0: 4 > 1 → row 1\n",
    "# - Col 1: 5 > 2 → row 1\n",
    "# - Col 2: 6 > 3 → row 1\n",
    "\n",
    "print(f\"argmax(dim=1):      {x.argmax(dim=1)}\")  # Index along dim 1 - tensor([2, 2])\n",
    "# argmax(dim=1) = [2, 2]\n",
    "# - Compares columns for each row:\n",
    "# - Row 0: max is 3 → col 2\n",
    "# - Row 1: max is 6 → col 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103jf1x5z5gn",
   "metadata": {},
   "source": [
    "### Arithmetic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "197e717e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "b:\n",
      " tensor([[5, 6],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Element-wise operations\n",
    "# =============================================================================\n",
    "\n",
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "print(\"a:\\n\", a)\n",
    "print(\"b:\\n\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a705c471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Element-wise operations:\n",
      "a + b:\n",
      "tensor([[ 6,  8],\n",
      "        [10, 12]])\n",
      "a * b:\n",
      "tensor([[ 5, 12],\n",
      "        [21, 32]])\n",
      "a ** 2:\n",
      "tensor([[ 1,  4],\n",
      "        [ 9, 16]])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise operations: +, -, *, /, **\n",
    "print(\"\\nElement-wise operations:\")\n",
    "print(f\"a + b:\\n{a + b}\")\n",
    "print(f\"a * b:\\n{a * b}\")\n",
    "print(f\"a ** 2:\\n{a ** 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c0a6fbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using torch functions:\n",
      "torch.add(a, b):\n",
      "tensor([[ 6,  8],\n",
      "        [10, 12]])\n",
      "torch.mul(a, b):\n",
      "tensor([[ 5, 12],\n",
      "        [21, 32]])\n",
      "torch.pow(a, 2):\n",
      "tensor([[ 1,  4],\n",
      "        [ 9, 16]])\n"
     ]
    }
   ],
   "source": [
    "# Same using torch functions\n",
    "print(\"\\nUsing torch functions:\")\n",
    "print(f\"torch.add(a, b):\\n{torch.add(a, b)}\")\n",
    "print(f\"torch.mul(a, b):\\n{torch.mul(a, b)}\")\n",
    "print(f\"torch.pow(a, 2):\\n{torch.pow(a, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ca862488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (shape torch.Size([2, 3])):\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "y (shape torch.Size([3, 2])):\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Matrix multiplication\n",
    "# =============================================================================\n",
    "\n",
    "# Note: Element-wise multiplication (*) is different from matrix multiplication!\n",
    "\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])  # Shape: (2, 3)\n",
    "y = torch.tensor([[1, 2], [3, 4], [5, 6]])  # Shape: (3, 2)\n",
    "\n",
    "print(f\"x (shape {x.shape}):\\n{x}\")\n",
    "print(f\"\\ny (shape {y.shape}):\\n{y}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ed53dd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.matmul(x, y) - shape torch.Size([2, 2]):\n",
      "tensor([[22, 28],\n",
      "        [49, 64]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication: (2x3) @ (3x2) = (2x2)\n",
    "result = torch.matmul(x, y)\n",
    "print(f\"\\ntorch.matmul(x, y) - shape {result.shape}:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "238b2a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x @ y:\n",
      "tensor([[22, 28],\n",
      "        [49, 64]])\n",
      "\n",
      "torch.mm(x, y):\n",
      "tensor([[22, 28],\n",
      "        [49, 64]])\n"
     ]
    }
   ],
   "source": [
    "# Alternative syntaxes\n",
    "print(f\"\\nx @ y:\\n{x @ y}\")  # @ operator\n",
    "print(f\"\\ntorch.mm(x, y):\\n{torch.mm(x, y)}\")  # Only for 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4921c372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "z @ z.T (shape torch.Size([2, 2])):\n",
      "tensor([[14, 32],\n",
      "        [32, 77]])\n"
     ]
    }
   ],
   "source": [
    "# Transpose for when dimensions don't match\n",
    "z = torch.tensor([[1, 2, 3], [4, 5, 6]])  # Shape: (2, 3)\n",
    "print(f\"\\nz @ z.T (shape {(z @ z.T).shape}):\\n{z @ z.T}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ulfi8cmsnv",
   "metadata": {},
   "source": [
    "### NumPy Interoperability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1952c04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor:\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "Shape: torch.Size([2, 3]), dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Tensor to NumPy\n",
    "# =============================================================================\n",
    "\n",
    "tensor = torch.tensor([[1., 2., 3.], [4., 5., 6.]])\n",
    "print(f\"Tensor:\\n{tensor}\")\n",
    "print(f\"Shape: {tensor.shape}, dtype: {tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "caadf01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NumPy array:\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "Shape: (2, 3), dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# Convert to NumPy - shares memory by default (on CPU)\n",
    "numpy_array = tensor.numpy()\n",
    "print(f\"\\nNumPy array:\\n{numpy_array}\")\n",
    "print(f\"Shape: {numpy_array.shape}, dtype: {numpy_array.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e8e69c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After tensor[0,0] = 999:\n",
      "tensor[0,0] = 999.0\n",
      "numpy_array[0,0] = 999.0\n"
     ]
    }
   ],
   "source": [
    "# They share memory - modifying one affects the other\n",
    "tensor[0, 0] = 999\n",
    "print(f\"\\nAfter tensor[0,0] = 999:\")\n",
    "print(f\"tensor[0,0] = {tensor[0,0]}\")\n",
    "print(f\"numpy_array[0,0] = {numpy_array[0,0]}\")  # Also changed!\n",
    "\n",
    "# To get a separate copy:\n",
    "# numpy_copy = tensor.clone().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f2b3f947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "numpy_array: \n",
      " [[0.73366788 0.9859529  0.88846274 0.61296789]\n",
      " [0.16225389 0.82216389 0.24644636 0.98026713]\n",
      " [0.89742194 0.35655514 0.51471602 0.73312017]]\n",
      "Shape of numpy_array:  (3, 4)\n",
      "Datatype of numpy_array:  float64\n"
     ]
    }
   ],
   "source": [
    "# or change numpy array to tensor\n",
    "numpy_array = np.random.rand(3,4)\n",
    "print(\"\\nnumpy_array: \\n\", numpy_array)\n",
    "print(\"Shape of numpy_array: \", numpy_array.shape)\n",
    "print(\"Datatype of numpy_array: \", numpy_array.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4e0690ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor_from_numpy: \n",
      " tensor([[0.7337, 0.9860, 0.8885, 0.6130],\n",
      "        [0.1623, 0.8222, 0.2464, 0.9803],\n",
      "        [0.8974, 0.3566, 0.5147, 0.7331]], dtype=torch.float64)\n",
      "Shape of tensor_from_numpy:  torch.Size([3, 4])\n",
      "Datatype of tensor_from_numpy:  torch.float64\n"
     ]
    }
   ],
   "source": [
    "tensor_from_numpy = torch.from_numpy(numpy_array)\n",
    "print(\"\\ntensor_from_numpy: \\n\", tensor_from_numpy)\n",
    "print(\"Shape of tensor_from_numpy: \", tensor_from_numpy.shape)\n",
    "print(\"Datatype of tensor_from_numpy: \", tensor_from_numpy.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xnj721e0tsj",
   "metadata": {},
   "source": [
    "### In-Place Operations\n",
    "\n",
    "Operations ending with `_` modify tensors in place (saves memory but be careful!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1316cc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: tensor([1., 2., 3.])\n",
      "Memory address: 0x76206a5a9a90\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# In-place operations (modify tensor directly)\n",
    "# =============================================================================\n",
    "\n",
    "x = torch.tensor([1., 2., 3.])\n",
    "print(f\"Original: {x}\")\n",
    "print(f\"Memory address: {hex(id(x))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "298c52d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After x.add_(5): tensor([6., 7., 8.])\n",
      "Memory address: 0x76206a5a9a90\n"
     ]
    }
   ],
   "source": [
    "# In-place operations have an underscore suffix\n",
    "x.add_(5)  # Same as x = x + 5, but modifies x directly\n",
    "print(f\"\\nAfter x.add_(5): {x}\")\n",
    "print(f\"Memory address: {hex(id(x))}\")  # Same address!\n",
    "\n",
    "# Common in-place operations:\n",
    "# add_(), sub_(), mul_(), div_()\n",
    "# zero_(), fill_(), copy_()\n",
    "# clamp_(), abs_(), sqrt_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "adf77790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After clamp_(0, 4): tensor([0., 0., 3., 4.])\n"
     ]
    }
   ],
   "source": [
    "# Example: clamp values to a range\n",
    "y = torch.tensor([-2., 0., 3., 5.])\n",
    "y.clamp_(min=0, max=4)\n",
    "print(f\"\\nAfter clamp_(0, 4): {y}\")\n",
    "\n",
    "# WARNING: In-place operations can break gradient computation\n",
    "# because they destroy the original values needed for backprop.\n",
    "# Avoid them in training code when requires_grad=True."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oitcuxkosv",
   "metadata": {},
   "source": [
    "### Cloning and Memory Sharing\n",
    "\n",
    "Understanding when tensors share memory is crucial for avoiding bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "49u6amahcao",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Clone vs View: Memory sharing\n",
    "# =============================================================================\n",
    "\n",
    "original = torch.tensor([1., 2., 3.])\n",
    "print(f\"Original tensor: {original}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "532ff31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "view() shares memory:\n",
      "  original: tensor([999.,   2.,   3.])\n",
      "  viewed:   tensor([999.,   2.,   3.])\n"
     ]
    }
   ],
   "source": [
    "# view() shares memory with original\n",
    "viewed = original.view(3, 1)\n",
    "print(\"view() shares memory:\")\n",
    "original[0] = 999\n",
    "print(f\"  original: {original}\")\n",
    "print(f\"  viewed:   {viewed.flatten()}\")  # Also changed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fe6821a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset\n",
    "original[0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f552a885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "clone() creates independent copy:\n",
      "  original: tensor([888.,   2.,   3.])\n",
      "  cloned:   tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "# clone() creates an independent copy\n",
    "cloned = original.clone()\n",
    "print(\"\\nclone() creates independent copy:\")\n",
    "original[0] = 888\n",
    "print(f\"  original: {original}\")\n",
    "print(f\"  cloned:   {cloned}\")  # Unchanged!\n",
    "\n",
    "# detach() vs clone():\n",
    "# - clone(): Creates a copy with same requires_grad\n",
    "# - detach(): Returns a view that doesn't require grad\n",
    "# - detach().clone(): Independent copy without gradient tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bckfnb483m",
   "metadata": {},
   "source": [
    "### Comparison Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2aqgyoyfpyr",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: \n",
      "tensor([1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Comparison and logical operations\n",
    "# =============================================================================\n",
    "\n",
    "x = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(\"Original tensor: \")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "212c9c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([1, 2, 3, 4, 5])\n",
      "x > 3:  tensor([False, False, False,  True,  True])\n",
      "x == 3: tensor([False, False,  True, False, False])\n",
      "x != 3: tensor([ True,  True, False,  True,  True])\n"
     ]
    }
   ],
   "source": [
    "# Comparison returns boolean tensors\n",
    "print(f\"x: {x}\")\n",
    "print(f\"x > 3:  {x > 3}\")\n",
    "print(f\"x == 3: {x == 3}\")\n",
    "print(f\"x != 3: {x != 3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d611b4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.gt(x, 3): tensor([False, False, False,  True,  True])\n",
      "torch.eq(x, 3): tensor([False, False,  True, False, False])\n"
     ]
    }
   ],
   "source": [
    "# Using torch functions\n",
    "print(f\"\\ntorch.gt(x, 3): {torch.gt(x, 3)}\")  # greater than\n",
    "print(f\"torch.eq(x, 3): {torch.eq(x, 3)}\")  # equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cad9ac5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x[x > 3]: tensor([4, 5])\n"
     ]
    }
   ],
   "source": [
    "# Boolean indexing - select elements that match condition\n",
    "print(f\"\\nx[x > 3]: {x[x > 3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8234af95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(x > 3).any(): True\n",
      "(x > 3).all(): False\n",
      "(x > 0).all(): True\n"
     ]
    }
   ],
   "source": [
    "# Any and all\n",
    "print(f\"\\n(x > 3).any(): {(x > 3).any()}\")  # At least one True\n",
    "print(f\"(x > 3).all(): {(x > 3).all()}\")  # All True\n",
    "print(f\"(x > 0).all(): {(x > 0).all()}\")  # All True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4929f4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "where(x > 2, x*10, x): tensor([ 1,  2, 30, 40, 50])\n"
     ]
    }
   ],
   "source": [
    "# Useful for conditional logic\n",
    "mask = x > 2\n",
    "result = torch.where(condition=mask, input=x * 10, other=x)  # If mask: x*10, else: x\n",
    "print(f\"\\nwhere(x > 2, x*10, x): {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54f283d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Deep Dive: Matrix Multiplication Functions\n",
    "\n",
    "PyTorch has several functions for matrix multiplication. Here's when to use each one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ea4f89",
   "metadata": {},
   "source": [
    "### torch.mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb62e7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " tensor([[1, 2],\n",
      "        [3, 4]]) \n",
      "\n",
      "b:\n",
      " tensor([[5, 6],\n",
      "        [7, 8]]) \n",
      "\n",
      "torch.mul(a, b):\n",
      " tensor([[ 5, 12],\n",
      "        [21, 32]]) \n",
      "\n",
      "Same as a * b:\n",
      " tensor([[ 5, 12],\n",
      "        [21, 32]])\n"
     ]
    }
   ],
   "source": [
    "# 1. torch.mul - Element-wise multiplication (works on any shape, no matrix multiplication)\n",
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[5, 6], [7, 8]])\n",
    "print(\"a:\\n\", a, \"\\n\")\n",
    "print(\"b:\\n\", b, \"\\n\")\n",
    "print(\"torch.mul(a, b):\\n\", torch.mul(a, b), \"\\n\")\n",
    "print(\"Same as a * b:\\n\", a * b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637a3580",
   "metadata": {},
   "source": [
    "### torch.mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6da9929b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (2x3):\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) \n",
      "\n",
      "shape of x: torch.Size([2, 3]), dimensions: 2\n",
      "x is a 2D tensor\n",
      "\n",
      "y (3x2):\n",
      " tensor([[ 7,  8],\n",
      "        [ 9, 10],\n",
      "        [11, 12]]) \n",
      "\n",
      "shape of y: torch.Size([3, 2]), dimensions: 2\n",
      "y is a 2D tensor\n",
      "\n",
      "torch.mm(x, y) (2x2):\n",
      " tensor([[ 58,  64],\n",
      "        [139, 154]]) \n",
      "\n",
      "\n",
      "torch.mm only works with 2D tensors\n",
      "vec: \n",
      " tensor([1, 2, 3]) \n",
      "\n",
      "shape of vec: torch.Size([3]), dimensions: 1\n",
      "vec is a 1D tensor\n",
      "Error with 1D tensors: self must be a matrix\n"
     ]
    }
   ],
   "source": [
    "# torch.mm - Strict 2D matrix multiplication (only works with 2D tensors)\n",
    "\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])  # 2x3\n",
    "print(\"x (2x3):\\n\", x, \"\\n\")\n",
    "print(f\"shape of x: {x.shape}, dimensions: {x.dim()}\")\n",
    "print(f\"x is a {x.dim()}D tensor\\n\")\n",
    "\n",
    "y = torch.tensor([[7, 8], [9, 10], [11, 12]])  # 3x2\n",
    "print(\"y (3x2):\\n\", y, \"\\n\")\n",
    "print(f\"shape of y: {y.shape}, dimensions: {y.dim()}\")\n",
    "print(f\"y is a {y.dim()}D tensor\\n\")\n",
    "print(\"torch.mm(x, y) (2x2):\\n\", torch.mm(x, y), \"\\n\")\n",
    "\n",
    "# torch.mm does NOT work with 1D or 3D tensors\n",
    "print(\"\\ntorch.mm only works with 2D tensors\")\n",
    "try:\n",
    "    vec = torch.tensor([1, 2, 3])\n",
    "    torch.mm(vec, vec)\n",
    "except RuntimeError as e:\n",
    "    print(\"vec: \\n\", vec, \"\\n\")\n",
    "    print(f\"shape of vec: {vec.shape}, dimensions: {vec.dim()}\")\n",
    "    print(f\"vec is a {vec.dim()}D tensor\")\n",
    "    print(f\"Error with 1D tensors: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f84aa6",
   "metadata": {},
   "source": [
    "### torch.matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6accb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.matmul(x, y):\n",
      " tensor([[ 58,  64],\n",
      "        [139, 154]])\n",
      "\n",
      "Works with 1D vectors (dot product):\n",
      "v1: tensor([1, 2, 3])\n",
      "shape of v1: torch.Size([3]), dimensions: 1\n",
      "v2: tensor([4, 5, 6])\n",
      "shape of v2: torch.Size([3]), dimensions: 1\n",
      "torch.matmul(v1, v2): tensor(32) \n",
      "\n",
      "Batch: \n",
      " tensor([[[ 0.8543,  1.4464, -0.6485,  1.5200],\n",
      "         [ 1.2156,  1.4097,  0.8729,  0.8012]],\n",
      "\n",
      "        [[ 1.1347,  0.0215, -1.4591,  0.0403],\n",
      "         [ 0.5238,  0.9281,  0.3071,  0.7228]],\n",
      "\n",
      "        [[ 0.3621,  0.7618,  1.2185, -0.4246],\n",
      "         [ 1.7410, -0.6459, -0.9263, -0.0328]]])\n",
      "batch shape: torch.Size([3, 2, 4]), dimensions: 3 \n",
      "\n",
      "mat: \n",
      " tensor([[-0.0286, -0.4385, -0.8938,  0.1958,  1.1579],\n",
      "        [ 2.4813,  0.6551,  0.3976, -0.9390,  0.0812],\n",
      "        [ 1.2785,  0.5465,  0.8102, -0.6476, -0.0157],\n",
      "        [ 0.5471,  1.6305, -0.0564,  0.6290, -0.9951]])\n",
      "mat shape: torch.Size([4, 5]), dimensions: 2\n",
      "\n",
      " torch.matmul(batch, mat) shape: torch.Size([3, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "# torch.matmul - General matrix multiplication (supports broadcasting)\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])  # 2x3\n",
    "y = torch.tensor([[7, 8], [9, 10], [11, 12]])  # 3x2\n",
    "print(\"torch.matmul(x, y):\\n\", torch.matmul(x, y))\n",
    "\n",
    "print(\"\\nWorks with 1D vectors (dot product):\")\n",
    "v1 = torch.tensor([1, 2, 3])\n",
    "v2 = torch.tensor([4, 5, 6])\n",
    "print(\"v1:\", v1)\n",
    "print(f\"shape of v1: {v1.shape}, dimensions: {v1.dim()}\")\n",
    "print(\"v2:\", v2)\n",
    "print(f\"shape of v2: {v2.shape}, dimensions: {v2.dim()}\")\n",
    "print(\"torch.matmul(v1, v2):\", torch.matmul(v1, v2), \"\\n\")\n",
    "\n",
    "# works with higher dimensions and broadcasts:\n",
    "# batch of matrices multiplied by single matrix\n",
    "batch = torch.randn(3, 2, 4)  # 3 matrices of size 2x4 \n",
    "mat = torch.randn(4, 5)  # single matrix of size 4x5\n",
    "\n",
    "# The single matrix (4x5) is broadcast and multiplied with each of the 3 matrices (2x4), giving 3 result matrices (2x5)\n",
    "result = torch.matmul(batch, mat)  # broadcasts to 3x2x5\n",
    "\n",
    "print(\"Batch: \\n\", batch)\n",
    "print(f\"batch shape: {batch.shape}, dimensions: {batch.dim()}\", \"\\n\")\n",
    "print(\"mat: \\n\", mat)\n",
    "print(f\"mat shape: {mat.shape}, dimensions: {mat.dim()}\")\n",
    "print(f\"\\n torch.matmul(batch, mat) shape: {result.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b482504c",
   "metadata": {},
   "source": [
    "### torch.bmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba5167af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch1 shape: torch.Size([10, 3, 4])\n",
      "batch2 shape: torch.Size([10, 4, 5])\n",
      "torch.bmm(batch1, batch2) shape: torch.Size([10, 3, 5])\n",
      "\n",
      "batch_a shape: torch.Size([5, 2, 3]), batch_b shape: torch.Size([3, 4])\n",
      "torch.matmul can broadcast: torch.Size([5, 2, 4])\n",
      "torch.bmm cannot broadcast: batch2 must be a 3D tensor\n"
     ]
    }
   ],
   "source": [
    "# torch.bmm requires EXACTLY 3D tensors with same batch size\n",
    "batch1 = torch.randn(10, 3, 4) # 10 matrices of size 3x4\n",
    "batch2 = torch.randn(10, 4, 5) # 10 matrices of size 4x5\n",
    "result = torch.bmm(batch1, batch2)  # results in 10x3x5\n",
    "print(f\"batch1 shape: {batch1.shape}\")\n",
    "print(f\"batch2 shape: {batch2.shape}\")\n",
    "print(f\"torch.bmm(batch1, batch2) shape: {result.shape}\")\n",
    "\n",
    "# Example where matmul works but bmm doesn't (broadcasting)\n",
    "batch_a = torch.randn(5, 2, 3)  # 5 matrices of 2x3\n",
    "batch_b = torch.randn(3, 4)     # single matrix of 3x4\n",
    "\n",
    "print(f\"\\nbatch_a shape: {batch_a.shape}, batch_b shape: {batch_b.shape}\")\n",
    "print(\"torch.matmul can broadcast:\", torch.matmul(batch_a, batch_b).shape)\n",
    "try:\n",
    "    torch.bmm(batch_a, batch_b)\n",
    "except RuntimeError as e:\n",
    "    print(f\"torch.bmm cannot broadcast: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebaf563",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c7d378f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a (2x3):\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "scalar: 10\n",
      "\n",
      "a + scalar (scalar is broadcast to match a's shape):\n",
      " tensor([[11, 12, 13],\n",
      "        [14, 15, 16]])\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting - Operating on tensors with different shapes\n",
    "# Broadcasting allows PyTorch to automatically expand tensors to compatible shapes\n",
    "\n",
    "# Scalar broadcasting\n",
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "scalar = 10\n",
    "print(\"a (2x3):\\n\", a)\n",
    "print(\"scalar:\", scalar)\n",
    "print(\"\\na + scalar (scalar is broadcast to match a's shape):\\n\", a + scalar) #scalar 10 becomes [[10, 10, 10], [10, 10, 10]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2bfda30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix (2x3):\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "vector (3,): tensor([10, 20, 30])\n",
      "\n",
      "matrix + vector:\n",
      " tensor([[11, 22, 33],\n",
      "        [14, 25, 36]])\n"
     ]
    }
   ],
   "source": [
    "# 1D to 2D broadcasting\n",
    "matrix = torch.tensor([[1, 2, 3], [4, 5, 6]])  # 2x3\n",
    "vector = torch.tensor([10, 20, 30])  # 3\n",
    "print(\"matrix (2x3):\\n\", matrix)\n",
    "print(\"vector (3,):\", vector)\n",
    "print(\"\\nmatrix + vector:\\n\", matrix + vector)\n",
    "\n",
    "#  vector [10, 20, 30] is broadcast to:\n",
    "# [[10, 20, 30],\n",
    "#  [10, 20, 30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3443423d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix (2x3):\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "col_vector (2x1):\n",
      " tensor([[10],\n",
      "        [20]])\n",
      "\n",
      "matrix + col_vector:\n",
      " tensor([[11, 12, 13],\n",
      "        [24, 25, 26]])\n"
     ]
    }
   ],
   "source": [
    "# Column vector broadcasting\n",
    "matrix = torch.tensor([[1, 2, 3], [4, 5, 6]])  # 2x3\n",
    "col_vector = torch.tensor([[10], [20]])  # 2x1\n",
    "print(\"matrix (2x3):\\n\", matrix)\n",
    "print(\"col_vector (2x1):\\n\", col_vector)\n",
    "print(\"\\nmatrix + col_vector:\\n\", matrix + col_vector)\n",
    "\n",
    "# col_vector [[10], [20]] is broadcast to:\n",
    "# [[10, 20, 30],\n",
    "#  [10, 20, 30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d98b9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a shape: torch.Size([3, 1, 4]) (3, 1, 4)\n",
      "b shape: torch.Size([1, 5, 4]) (1, 5, 4)\n",
      "Result shape: torch.Size([3, 5, 4])\n"
     ]
    }
   ],
   "source": [
    "# \"Two tensors are broadcastable if:\"\n",
    "# \"1. Each tensor has at least one dimension, AND\"\n",
    "# \"2. When iterating over dimensions from right to left:\n",
    "#     - Dimensions are equal, OR\"\n",
    "#     - One of them is 1, OR\"\n",
    "#     - One of them doesn't exist\"\n",
    "\n",
    "# Example of compatible shapes\n",
    "a = torch.randn(3, 1, 4)\n",
    "b = torch.randn(1, 5, 4)\n",
    "c = a + b\n",
    "print(f\"\\na shape: {a.shape} (3, 1, 4)\")\n",
    "print(f\"b shape: {b.shape} (1, 5, 4)\")\n",
    "print(f\"Result shape: {c.shape}\")\n",
    "\n",
    "#   a: (3, 1, 4)\n",
    "#   b: (1, 5, 4)\n",
    "#       ↑  ↑  ↑\n",
    "#     dim0 dim1 dim2\n",
    "\n",
    "# Dim 2 (rightmost): a[4] vs b[4] → 4 == 4 ✓ Result: 4\n",
    "# Dim 1 (middle): a[1] vs b[5] → 1 can broadcast to 5 ✓ Result: 5\n",
    "#     - When one dimension is 1, it stretches/repeats to match the other\n",
    "# Dim 0 (leftmost): a[3] vs b[1] → 1 can broadcast to 3 ✓ Result: 3\n",
    "#     - Again, 1 broadcasts to match 3\n",
    "\n",
    "# Final result: (3, 5, 4)\n",
    "\n",
    "# What actually happens:\n",
    "# - Tensor a (3, 1, 4): The middle dimension [1] is repeated 5 times\n",
    "# - Tensor b (1, 5, 4): The first dimension [1] is repeated 3 times\n",
    "\n",
    "# So effectively:\n",
    "# - a becomes (3, 5, 4) by copying its single column 5 times\n",
    "# - b becomes (3, 5, 4) by copying its single matrix 3 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "071f34ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([3, 4]) (3, 4)\n",
      "y shape: torch.Size([3, 5]) (3, 5)\n",
      "\n",
      "Dimension by dimension:\n",
      "  Dim 1: 4 != 5 and neither is 1 ✗\n",
      "\n",
      "Error: The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 1\n"
     ]
    }
   ],
   "source": [
    "# Example 5: Incompatible shapes\n",
    "x = torch.randn(3, 4)\n",
    "y = torch.randn(3, 5)\n",
    "print(f\"x shape: {x.shape} (3, 4)\")\n",
    "print(f\"y shape: {y.shape} (3, 5)\")\n",
    "print(\"\\nDimension by dimension:\")\n",
    "print(\"  Dim 1: 4 != 5 and neither is 1 ✗\")\n",
    "try:\n",
    "    z = x + y\n",
    "except RuntimeError as e:\n",
    "    print(f\"\\nError: {e}\")\n",
    "\n",
    "\n",
    "#   x: (3, 4)\n",
    "#   y: (3, 5)\n",
    "#       ↑  ↑\n",
    "#      dim0 dim1\n",
    "\n",
    "# 1. Dim 1 (rightmost): x[4] vs y[5] → 4 ≠ 5 and neither is 1 ✗ FAIL\n",
    "\n",
    "# Broadcasting stops here!\n",
    "\n",
    "# Why it fails:\n",
    "# - For broadcasting to work, dimensions must be:\n",
    "# - Equal (e.g., 4 == 4), OR\n",
    "# - One of them is 1 (e.g., 1 can broadcast to any size), OR\n",
    "# - One doesn't exist (e.g., (3,) can broadcast with (3, 4))\n",
    "\n",
    "# Since 4 ≠ 5 and neither dimension is 1, PyTorch cannot automatically expand either tensor to make them compatible.\n",
    "\n",
    "# If we wanted them to work:\n",
    "# - Change y to (3, 4) → dimensions match\n",
    "# - Change y to (3, 1) → the 1 can broadcast to 4\n",
    "# - Change x to (3, 1) → the 1 can broadcast to 5\n",
    "\n",
    "# But with 4 and 5, there's no way to broadcast - PyTorch won't guess which one you want!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7c9e12",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Quick Reference\n",
    "\n",
    "### Tensor Creation\n",
    "| Function | Description |\n",
    "|----------|-------------|\n",
    "| `torch.tensor(data)` | Create from Python list/tuple |\n",
    "| `torch.from_numpy(arr)` | Convert NumPy array (shares memory) |\n",
    "| `torch.zeros(shape)` | All zeros |\n",
    "| `torch.ones(shape)` | All ones |\n",
    "| `torch.rand(shape)` | Random [0, 1) |\n",
    "| `torch.randn(shape)` | Random normal (mean=0, std=1) |\n",
    "| `torch.arange(start, end, step)` | Evenly spaced values |\n",
    "| `torch.eye(n)` | Identity matrix |\n",
    "\n",
    "### Shape Operations\n",
    "| Operation | Description |\n",
    "|-----------|-------------|\n",
    "| `.view(shape)` | Reshape (must be contiguous) |\n",
    "| `.reshape(shape)` | Reshape (works on any tensor) |\n",
    "| `.squeeze()` | Remove dims of size 1 |\n",
    "| `.unsqueeze(dim)` | Add dim of size 1 |\n",
    "| `.flatten()` | Collapse to 1D |\n",
    "| `.permute(dims)` | Reorder dimensions |\n",
    "| `.T` | Transpose (2D only) |\n",
    "\n",
    "### Key Operations\n",
    "| Operation | Description |\n",
    "|-----------|-------------|\n",
    "| `+`, `-`, `*`, `/` | Element-wise arithmetic |\n",
    "| `@`, `torch.matmul()` | Matrix multiplication |\n",
    "| `.sum(dim)` | Sum along dimension |\n",
    "| `.mean(dim)` | Mean along dimension |\n",
    "| `.max(dim)` | Max along dimension |\n",
    "\n",
    "### Device & Type\n",
    "| Operation | Description |\n",
    "|-----------|-------------|\n",
    "| `.to('cuda')` | Move to GPU |\n",
    "| `.to('cpu')` | Move to CPU |\n",
    "| `.float()` | Convert to float32 |\n",
    "| `.long()` | Convert to int64 |\n",
    "| `.clone()` | Create independent copy |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-cookbook-for-noobs (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
